Paper,"Fairness-1:
Define any potential sources of bias from an early stage","Fairness-2:
Collect data on individuals’ attributes, when possible","Fairness-3:
Evaluate potential biases and bias correction measures","Universality-1:
Define intended clinical settings and cross-setting variations","Universality-2:
Use community-defined standards (e.g. clinical definitions, technical standards)","Universality-3:
Evaluate using external datasets and/or multiple sites","Universality-4:
Evaluate and demonstrate local clinical validity","Traceability-1:
Implement a risk management process throughout the AI lifecycle","Traceability-2:
Provide documentation (e.g. technical, clinical)","Traceability-3:
Define mechanisms for quality control of the AI inputs and outputs","Traceability-4:
Implement a system for periodic auditing and updating","Traceability-5:
Implement a logging system for usage recording","Traceability-6:
Establish mechanisms for human oversight and governance","Usability-1:
Define intended use and user requirements from an early stage","Usability-2:
Provide training materials and activities (e.g. tutorials, hands-on sessions)","Usability-3:
Evaluate user experience and acceptance with independent end-users","Usability-4:
Evaluate clinical utility and safety (e.g. effectiveness, harm, cost-benefit)","Robustness-1:
Define sources of data variation from an early stage","Robustness-2:
Train with representative real-world data","Robustness-3:
Evaluate and optimise robustness against real-world variations","Explainability-1:
Define the need and requirements for explainability with end-users","Explainability-2:
Evaluate explainability with end-users (e.g. correctness, impact on users)","General-1:
Engage inter-disciplinary stakeholders throughout the AI lifecycle","General-2:
Implement measures for data privacy and security","General-3:
Define adequate evaluation plan (e.g. datasets, metrics, reference methods)","General-4:
Identify and comply with applicable AI regulatory requirements","General-5:
Investigate and address ethical issues","General-6:
Investigate and address social and societal issues"
Do_2021_Multi-Level Seg-Unet Model with Global and Patch-Based X-ray Images for Knee Bone Tumor Detection,No potential biases were discussed prior to AI development,No relevant attributes of the patient were collected;,Biases were investigated and reported,The clinical setting was not reported ,Yes,This study only used single center data --> no external validation;,"local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,Monitoring or quality control measures have been implemented for either the inputs or outputs ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, however intended use and end-user requirement was described; OR, multiple stakeholders were present for AI development, no intented use or requirement was decribed",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has not been discussed,The representative of the training data to the real-world data was evaluated,The AI tool has not been evaluated against real-world data (test data),"At least one of the following areas is discussed: (i) the goal of the explanations (eg global description of the model’s behaviour vs local explanation of each AI decision), (ii) the most suitable approach for AI explainability and (iii) the potential limitations to anticipate and monitor (eg over-reliance of the end-users on the AI decision)",Explainability has not been defined or not evaluated with end-users,Yes,Yes,Evaluation was not conducted using standardized and best practices,No,No,No
Foreman_2023_Development and Evaluation of MR-Based Radiogenomic Models to Differentiate Atypical Lipomatous Tumors from Lipomas,No potential biases were discussed prior to AI development,"More than two attributes in the list were collected, OR with other attributes",Biases were neither investigated nor corrected for,The clinical setting was not reported ,Yes,"Evaluation was performed using external dataset from one other site (or same source, eg public available);",local clinical validity has been discussed and evaluated,Risks regarding the AI lifecycle have not been described,No documentation has been provided,No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, however intended use and end-user requirement was described; OR, multiple stakeholders were present for AI development, no intented use or requirement was decribed",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has been evaluated against real-world data (test data),Explainibility has not been defined at the design phase,Explainability has not been defined or not evaluated with end-users,Yes,Yes,The AI tool was compared to current standard practice (ie evaluation metrics on test set should be compared to same metrics for current clinical tests - so for example how did it compare to radiologists),No,No,No
Liu_2022_Value of contrast-enhanced CT based radiomic machine learning algorithm in differentiating gastrointestinal stromal tumors with KIT exon 11 mutation: a two-center study,No potential biases were discussed prior to AI development,"More than two attributes in the list were collected, OR with other attributes","Biases were also corrected for by mitigation measures (In case of no biases found, 3 also applies)",The clinical setting was not reported ,Yes,This study only used single center data --> no external validation;,"local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, however intended use and end-user requirement was described; OR, multiple stakeholders were present for AI development, no intented use or requirement was decribed",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has not been evaluated against real-world data (test data),Explainibility has not been defined at the design phase,Explainability has not been defined or not evaluated with end-users,Yes,Yes,Evaluation was not conducted using standardized and best practices,No,No,No
Hajianfar_2023_Artificial intelligence-based analysis of whole-body bone scintigraphy: The quest for the optimal deep learning algorithm and comparison with human observer performance,No potential biases were discussed prior to AI development,"At least the two attributes in the list collected; (list :sex OR gender, age, ethnicity, risk factors(as 1 item), comorbidities or disabilities)",Biases were neither investigated nor corrected for,The clinical setting was not reported ,No,This study only used single center data --> no external validation;,"local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, however intended use and end-user requirement was described; OR, multiple stakeholders were present for AI development, no intented use or requirement was decribed",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has not been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has been evaluated against real-world data (test data),Explainibility has not been defined at the design phase,Explainability has not been defined or not evaluated with end-users,Yes,No,Evaluation was not conducted using standardized and best practices,No,No,No
Gao_2020_Treatment effect prediction for sarcoma patients treated with preoperative radiotherapy using radiomics features from longitudinal diffusion-weighted MRIs,No potential biases were discussed prior to AI development,"At least the two attributes in the list collected; (list :sex OR gender, age, ethnicity, risk factors(as 1 item), comorbidities or disabilities)",Biases were neither investigated nor corrected for,The clinical setting was not reported ,Yes,This study only used single center data --> no external validation;,"local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, however intended use and end-user requirement was described; OR, multiple stakeholders were present for AI development, no intented use or requirement was decribed",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has not been evaluated against real-world data (test data),Explainibility has not been defined at the design phase,Explainability has not been defined or not evaluated with end-users,Yes,Yes,Evaluation was not conducted using standardized and best practices,No,No,No
Gitto_2022_Diffusion‑weighted MRI radiomics of spine bone tumors: feature stability and machine learning‑based classification performance,No potential biases were discussed prior to AI development,"At least the two attributes in the list collected; (list :sex OR gender, age, ethnicity, risk factors(as 1 item), comorbidities or disabilities)",Biases were neither investigated nor corrected for,The clinical setting was not reported ,Yes,This study only used single center data --> no external validation;,"local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, however intended use and end-user requirement was described; OR, multiple stakeholders were present for AI development, no intented use or requirement was decribed",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has not been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has not been evaluated against real-world data (test data),Explainibility has not been defined at the design phase,Explainability has not been defined or not evaluated with end-users,Yes,Yes,Evaluation was not conducted using standardized and best practices,No,No,No
Gitto_2023_MRI radiomics‑based machine learning for classification of deep‑seated lipoma and atypical lipomatous tumor of the extremities,No potential biases were discussed prior to AI development,"At least the two attributes in the list collected; (list :sex OR gender, age, ethnicity, risk factors(as 1 item), comorbidities or disabilities)",Biases were investigated and reported,The clinical setting was not reported ,Yes,"Evaluation was performed using external dataset from one other site (or same source, eg public available);",local clinical validity has been discussed and evaluated,Risks regarding the AI lifecycle have not been described,No documentation has been provided,No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, however intended use and end-user requirement was described; OR, multiple stakeholders were present for AI development, no intented use or requirement was decribed",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has been evaluated against real-world data (test data),Explainibility has not been defined at the design phase,Explainability has not been defined or not evaluated with end-users,Yes,Yes,A seperate test set was used to evaluate the AI tool and reported on using appropriate evaluation metrics (eg sensitivity and specificity) ,No,No,No
He_2020_Deep learning-based classification of primary bone tumors on radiographs: A preliminary study,No potential biases were discussed prior to AI development,"At least the two attributes in the list collected; (list :sex OR gender, age, ethnicity, risk factors(as 1 item), comorbidities or disabilities)",Biases were neither investigated nor corrected for,"Clinical setting outlined (eg primary healthcare centres, hospitals, home care, low vs high-resource settings, one or multiple countries)",Yes,Evaluation was performed using external dataset from multiple sites;,"local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,Documentation about 1-2 points (see decription) have been provided),No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, however intended use and end-user requirement was described; OR, multiple stakeholders were present for AI development, no intented use or requirement was decribed",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has not been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has been evaluated against real-world data (test data),Explainibility has not been defined at the design phase,Explainability has not been defined or not evaluated with end-users,Yes,Yes,A seperate test set was used to evaluate the AI tool and reported on using appropriate evaluation metrics (eg sensitivity and specificity) ,No,No,No
Shao_2021_Building Radiomics Models Based on Triple-Phase CT Images Combining Clinical Features for Discriminating the Risk Rating in Gastrointestinal Stromal Tumors,No potential biases were discussed prior to AI development,"More than two attributes in the list were collected, OR with other attributes",Biases were investigated and reported,The clinical setting was not reported ,Yes,This study only used single center data --> no external validation;,"local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, and no intended use and user requirement was described",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has not been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has not been evaluated against real-world data (test data),Explainibility has not been defined at the design phase,Explainability has not been defined or not evaluated with end-users,No,Yes,Evaluation was not conducted using standardized and best practices,No,No,No
Wang_2022_A Multiparametric Method Based on Clinical and CT-Based Radiomics to Predict the Expression of p53 and VEGF in Patients With Spinal Giant Cell Tumor of Bone,"Potential biases in at least 1 group (group attributes, medical profile, human biases) were discussed prior to AI development","More than two attributes in the list were collected, OR with other attributes",Biases were investigated and reported,The clinical setting was not reported ,Yes,This study only used single center data --> no external validation;,"local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, however intended use and end-user requirement was described; OR, multiple stakeholders were present for AI development, no intented use or requirement was decribed",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has not been evaluated against real-world data (test data),Explainibility has not been defined at the design phase,Explainability has not been defined or not evaluated with end-users,Yes,Yes,Evaluation was not conducted using standardized and best practices,No,No,No
Wang_2019_Building CT Radiomics-Based Models for Preoperatively Predicting Malignant Potential and Mitotic Count of Gastrointestinal Stromal Tumors,No potential biases were discussed prior to AI development,"At least the two attributes in the list collected; (list :sex OR gender, age, ethnicity, risk factors(as 1 item), comorbidities or disabilities)",Biases were neither investigated nor corrected for,The clinical setting was not reported ,Yes,This study only used single center data --> no external validation;,"local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, however intended use and end-user requirement was described; OR, multiple stakeholders were present for AI development, no intented use or requirement was decribed",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has not been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has not been evaluated against real-world data (test data),Explainibility has not been defined at the design phase,Explainability has not been defined or not evaluated with end-users,Yes,Yes,Evaluation was not conducted using standardized and best practices,No,No,No
Zhuo_2022_Ultrasound radiomics modelbased nomogram for predicting the risk Stratification of gastrointestinal stromal tumors,No potential biases were discussed prior to AI development,"More than two attributes in the list were collected, OR with other attributes",Biases were investigated and reported,The clinical setting was not reported ,Yes,This study only used single center data --> no external validation;,"local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, and no intended use and user requirement was described",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has not been evaluated against real-world data (test data),Explainibility has not been defined at the design phase,Explainability has not been defined or not evaluated with end-users,No,Yes,Evaluation was not conducted using standardized and best practices,No,No,No
Zheng_2022_Combined model based on enhanced CT texture features in liver metastasis prediction of high‑risk gastrointestinal stromal tumors,No potential biases were discussed prior to AI development,"At least the two attributes in the list collected; (list :sex OR gender, age, ethnicity, risk factors(as 1 item), comorbidities or disabilities)",Biases were investigated and reported,The clinical setting was not reported ,Yes,This study only used single center data --> no external validation;,"local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, however intended use and end-user requirement was described; OR, multiple stakeholders were present for AI development, no intented use or requirement was decribed",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has not been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has not been evaluated against real-world data (test data),Explainibility has not been defined at the design phase,Explainability has not been defined or not evaluated with end-users,Yes,Yes,Evaluation was not conducted using standardized and best practices,No,No,No
Zhao_2021_CT Radiomics for the Preoperative Prediction of Ki67 Index in Gastrointestinal Stromal Tumors: A Multi-Center Study,No potential biases were discussed prior to AI development,"At least the two attributes in the list collected; (list :sex OR gender, age, ethnicity, risk factors(as 1 item), comorbidities or disabilities)",Biases were neither investigated nor corrected for,The clinical setting was not reported ,No,Evaluation was performed using external dataset from multiple sites;,"local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, however intended use and end-user requirement was described; OR, multiple stakeholders were present for AI development, no intented use or requirement was decribed",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has not been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has been evaluated against real-world data (test data),Explainibility has not been defined at the design phase,Explainability has not been defined or not evaluated with end-users,Yes,Yes,Evaluation was not conducted using standardized and best practices,No,No,No
Zhang_2019_Soft Tissue Sarcomas: Preoperative Predictive Histopathological Grading Based on Radiomics of MRI,No potential biases were discussed prior to AI development,"At least the two attributes in the list collected; (list :sex OR gender, age, ethnicity, risk factors(as 1 item), comorbidities or disabilities)",Biases were neither investigated nor corrected for,The clinical setting was not reported ,No,This study only used single center data --> no external validation;,"local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, and no intended use and user requirement was described",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has not been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has not been evaluated against real-world data (test data),Explainibility has not been defined at the design phase,Explainability has not been defined or not evaluated with end-users,Yes,Yes,Evaluation was not conducted using standardized and best practices,No,No,No
Zhang_2020_Comparison of malignancy-prediction efficiency between contrast and non-contract CT-based radiomics features in gastrointestinal stromal tumors: A multicenter study,No potential biases were discussed prior to AI development,"More than two attributes in the list were collected, OR with other attributes",Biases were investigated and reported,The clinical setting was not reported ,Yes,Evaluation was performed using external dataset from multiple sites;,local clinical validity has been discussed and evaluated,Risks regarding the AI lifecycle have not been described,No documentation has been provided,No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, however intended use and end-user requirement was described; OR, multiple stakeholders were present for AI development, no intented use or requirement was decribed",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has been evaluated against real-world data (test data),Explainibility has not been defined at the design phase,Explainability has not been defined or not evaluated with end-users,Yes,Yes,A seperate test set was used to evaluate the AI tool and reported on using appropriate evaluation metrics (eg sensitivity and specificity) ,No,No,No
Zhang_2020_Computed tomography‑based radiomics model for discriminating the risk stratification of gastrointestinal stromal tumors,No potential biases were discussed prior to AI development,"At least the two attributes in the list collected; (list :sex OR gender, age, ethnicity, risk factors(as 1 item), comorbidities or disabilities)",Biases were investigated and reported,The clinical setting was not reported ,Yes,This study only used single center data --> no external validation;,"local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, however intended use and end-user requirement was described; OR, multiple stakeholders were present for AI development, no intented use or requirement was decribed",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has not been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has not been evaluated against real-world data (test data),Explainibility has not been defined at the design phase,Explainability has not been defined or not evaluated with end-users,Yes,Yes,Evaluation was not conducted using standardized and best practices,No,No,No
Yue_2022_Multi-parametric MRI-based radiomics for the diagnosis of malignant soft-tissue tumor,No potential biases were discussed prior to AI development,"More than two attributes in the list were collected, OR with other attributes",Biases were investigated and reported,The clinical setting was not reported ,Yes,This study only used single center data --> no external validation;,"local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, however intended use and end-user requirement was described; OR, multiple stakeholders were present for AI development, no intented use or requirement was decribed",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has not been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has not been evaluated against real-world data (test data),Explainibility has not been defined at the design phase,Explainability has not been defined or not evaluated with end-users,Yes,Yes,A seperate test set was used to evaluate the AI tool and reported on using appropriate evaluation metrics (eg sensitivity and specificity) ,No,No,No
"Yue_2022_Clinical‑Radiomics Nomogram from T1W, T1CE, and T2FS MRI for Improving Diagnosis of Soft‑Tissue Sarcoma",No potential biases were discussed prior to AI development,"More than two attributes in the list were collected, OR with other attributes",Biases were investigated and reported,The clinical setting was not reported ,Yes,This study only used single center data --> no external validation;,"local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, however intended use and end-user requirement was described; OR, multiple stakeholders were present for AI development, no intented use or requirement was decribed",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has not been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has not been evaluated against real-world data (test data),Explainibility has not been defined at the design phase,Explainability has not been defined or not evaluated with end-users,Yes,Yes,A seperate test set was used to evaluate the AI tool and reported on using appropriate evaluation metrics (eg sensitivity and specificity) ,No,No,No
Yin_2023_The potential for different computed tomography-based machine learning networks to automatically segment and differentiate pelvic and sacral osteosarcoma from Ewing’s sarcoma,No potential biases were discussed prior to AI development,"At least the two attributes in the list collected; (list :sex OR gender, age, ethnicity, risk factors(as 1 item), comorbidities or disabilities)",Biases were neither investigated nor corrected for,The clinical setting was not reported ,Yes,This study only used single center data --> no external validation;,"local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, however intended use and end-user requirement was described; OR, multiple stakeholders were present for AI development, no intented use or requirement was decribed",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has not been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has not been evaluated against real-world data (test data),"At least one of the following areas is discussed: (i) the goal of the explanations (eg global description of the model’s behaviour vs local explanation of each AI decision), (ii) the most suitable approach for AI explainability and (iii) the potential limitations to anticipate and monitor (eg over-reliance of the end-users on the AI decision)",Explainability has not been defined or not evaluated with end-users,Yes,Yes,Evaluation was not conducted using standardized and best practices,No,No,No
Sudjai_2023_Tumor-to-bone distance and radiomic features on MRI distinguish intramuscular lipomas from well-differentiated liposarcomas,No potential biases were discussed prior to AI development,"At least the two attributes in the list collected; (list :sex OR gender, age, ethnicity, risk factors(as 1 item), comorbidities or disabilities)",Biases were neither investigated nor corrected for,The clinical setting was not reported ,Yes,This study only used single center data --> no external validation;,"local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, and no intended use and user requirement was described",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has not been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has not been evaluated against real-world data (test data),Explainibility has not been defined at the design phase,Explainability has not been defined or not evaluated with end-users,No,Yes,Evaluation was not conducted using standardized and best practices,No,No,No
Peeken_2019_Tumor grading of soft tissue sarcomas using MRI-based radiomics,No potential biases were discussed prior to AI development,"More than two attributes in the list were collected, OR with other attributes","Biases were also corrected for by mitigation measures (In case of no biases found, 3 also applies)",The clinical setting was not reported ,Yes,This study only used single center data --> no external validation;,"local clinical validity has been discussed and evaluated and if needed, mitigation strategies have been deployed to deal with this local clinical validity",Risks regarding the AI lifecycle have not been described,No documentation has been provided,No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, however intended use and end-user requirement was described; OR, multiple stakeholders were present for AI development, no intented use or requirement was decribed",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has not been evaluated against real-world data (test data),Explainibility has not been defined at the design phase,Explainability has not been defined or not evaluated with end-users,Yes,Yes,A seperate test set was used to evaluate the AI tool and reported on using appropriate evaluation metrics (eg sensitivity and specificity) ,No,No,No
Liu_2021_TN-USMA Net: Triple normalization-based gastrointestinal stromal tumors classification on multicenter EUS images with ultrasound-specific pretraining and meta attention,No potential biases were discussed prior to AI development,No relevant attributes of the patient were collected;,Biases were neither investigated nor corrected for,The clinical setting was not reported ,Yes,"Evaluation was performed using external dataset from one other site (or same source, eg public available);","local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, however intended use and end-user requirement was described; OR, multiple stakeholders were present for AI development, no intented use or requirement was decribed",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has not been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has not been evaluated against real-world data (test data),Explainibility has not been defined at the design phase,Explainability has not been defined or not evaluated with end-users,Yes,Yes,A seperate test set was used to evaluate the AI tool and reported on using appropriate evaluation metrics (eg sensitivity and specificity) ,No,No,No
Erdem_2023_The use of radiomics and machine learning for the differentiation of chondrosarcoma from enchondroma,No potential biases were discussed prior to AI development,No relevant attributes of the patient were collected;,Biases were neither investigated nor corrected for,The clinical setting was not reported ,Yes,This study only used single center data --> no external validation;,"local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, and no intended use and user requirement was described",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has not been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has not been evaluated against real-world data (test data),Explainibility has not been defined at the design phase,Explainability has not been defined or not evaluated with end-users,No,Yes,Evaluation was not conducted using standardized and best practices,No,No,No
Wu_2018_Survival Prediction in High-grade Osteosarcoma Using Radiomics of Diagnostic Computed Tomography,No potential biases were discussed prior to AI development,"More than two attributes in the list were collected, OR with other attributes",Biases were investigated and reported,The clinical setting was not reported ,Yes,This study only used single center data --> no external validation;,"local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, however intended use and end-user requirement was described; OR, multiple stakeholders were present for AI development, no intented use or requirement was decribed",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has not been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has not been evaluated against real-world data (test data),Explainibility has not been defined at the design phase,Explainability has not been defined or not evaluated with end-users,Yes,Yes,A seperate test set was used to evaluate the AI tool and reported on using appropriate evaluation metrics (eg sensitivity and specificity) ,No,No,No
Yin_2020_Machine and Deep Learning Based Radiomics Models for Preoperative Prediction of Benign and Malignant Sacral Tumors,No potential biases were discussed prior to AI development,"At least the two attributes in the list collected; (list :sex OR gender, age, ethnicity, risk factors(as 1 item), comorbidities or disabilities)",Biases were neither investigated nor corrected for,The clinical setting was not reported ,Yes,This study only used single center data --> no external validation;,"local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, however intended use and end-user requirement was described; OR, multiple stakeholders were present for AI development, no intented use or requirement was decribed",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has not been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has not been evaluated against real-world data (test data),Explainibility has not been defined at the design phase,Explainability has not been defined or not evaluated with end-users,Yes,Yes,A seperate test set was used to evaluate the AI tool and reported on using appropriate evaluation metrics (eg sensitivity and specificity) ,No,No,No
Potter_2023_Automated Bone Tumor Segmentation and Classification as Benign or Malignant Using Computed Tomographic Imaging,No potential biases were discussed prior to AI development,"At least the two attributes in the list collected; (list :sex OR gender, age, ethnicity, risk factors(as 1 item), comorbidities or disabilities)",Biases were neither investigated nor corrected for,The clinical setting was not reported ,No,This study only used single center data --> no external validation;,"local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, and no intended use and user requirement was described",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has not been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has not been evaluated against real-world data (test data),Explainibility has not been defined at the design phase,Explainability has not been defined or not evaluated with end-users,No,Yes,Evaluation was not conducted using standardized and best practices,No,No,No
Yang_2021_MRI Texture-Based Models for Predicting Mitotic Index and Risk Classification of Gastrointestinal Stromal Tumors,No potential biases were discussed prior to AI development,"More than two attributes in the list were collected, OR with other attributes",Biases were investigated and reported,The clinical setting was not reported ,Yes,This study only used single center data --> no external validation;,"local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, however intended use and end-user requirement was described; OR, multiple stakeholders were present for AI development, no intented use or requirement was decribed",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has not been evaluated against real-world data (test data),Explainibility has not been defined at the design phase,Explainability has not been defined or not evaluated with end-users,Yes,Yes,A seperate test set was used to evaluate the AI tool and reported on using appropriate evaluation metrics (eg sensitivity and specificity) ,No,No,No
Thornhill_2014_Differentiation of Lipoma From Liposarcoma on MRI Using Texture and Shape Analysis,No potential biases were discussed prior to AI development,No relevant attributes of the patient were collected;,Biases were neither investigated nor corrected for,The clinical setting was not reported ,Yes,This study only used single center data --> no external validation;,"local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, however intended use and end-user requirement was described; OR, multiple stakeholders were present for AI development, no intented use or requirement was decribed",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has not been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has not been evaluated against real-world data (test data),Explainibility has not been defined at the design phase,Explainability has not been defined or not evaluated with end-users,Yes,Yes,The AI tool was compared to current standard practice (ie evaluation metrics on test set should be compared to same metrics for current clinical tests - so for example how did it compare to radiologists),No,No,No
Starmans_2022_Differential Diagnosis and Molecular Stratification of Gastrointestinal Stromal Tumors on CT Images Using a Radiomics Approach,No potential biases were discussed prior to AI development,"More than two attributes in the list were collected, OR with other attributes",Biases were investigated and reported,"Clinical setting outlined (eg primary healthcare centres, hospitals, home care, low vs high-resource settings, one or multiple countries)",Yes,This study only used single center data --> no external validation;,"local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,Documentation about 1-2 points (see decription) have been provided),No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, however intended use and end-user requirement was described; OR, multiple stakeholders were present for AI development, no intented use or requirement was decribed",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has not been evaluated against real-world data (test data),Explainibility has not been defined at the design phase,Explainability has not been defined or not evaluated with end-users,Yes,Yes,The AI tool was compared to current standard practice (ie evaluation metrics on test set should be compared to same metrics for current clinical tests - so for example how did it compare to radiologists),No,No,No
Timbergen_2020_Differential diagnosis and mutation stratification of desmoid-type fibromatosis on MRI using radiomics,No potential biases were discussed prior to AI development,"More than two attributes in the list were collected, OR with other attributes",Biases were investigated and reported,The clinical setting was not reported ,Yes,This study only used single center data --> no external validation;,"local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,Documentation about 1-2 points (see decription) have been provided),No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, however intended use and end-user requirement was described; OR, multiple stakeholders were present for AI development, no intented use or requirement was decribed",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has not been evaluated against real-world data (test data),Explainibility has not been defined at the design phase,Explainability has not been defined or not evaluated with end-users,Yes,Yes,The AI tool was compared to current standard practice (ie evaluation metrics on test set should be compared to same metrics for current clinical tests - so for example how did it compare to radiologists),No,No,No
Yang_2022_Application of radiomics in predicting the preoperative risk stratification of gastric stromal tumors,No potential biases were discussed prior to AI development,"At least the two attributes in the list collected; (list :sex OR gender, age, ethnicity, risk factors(as 1 item), comorbidities or disabilities)",Biases were investigated and reported,The clinical setting was not reported ,Yes,This study only used single center data --> no external validation;,"local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, however intended use and end-user requirement was described; OR, multiple stakeholders were present for AI development, no intented use or requirement was decribed",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has not been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has not been evaluated against real-world data (test data),Explainibility has not been defined at the design phase,Explainability has not been defined or not evaluated with end-users,Yes,Yes,A seperate test set was used to evaluate the AI tool and reported on using appropriate evaluation metrics (eg sensitivity and specificity) ,No,No,No
Xu_2021_Prediction of neoadjuvant chemotherapy response in high-grade osteosarcoma: added value of non-tumorous bone radiomics using CT images,No potential biases were discussed prior to AI development,"More than two attributes in the list were collected, OR with other attributes",Biases were neither investigated nor corrected for,The clinical setting was not reported ,Yes,This study only used single center data --> no external validation;,"local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, however intended use and end-user requirement was described; OR, multiple stakeholders were present for AI development, no intented use or requirement was decribed",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has not been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has not been evaluated against real-world data (test data),Explainibility has not been defined at the design phase,Explainability has not been defined or not evaluated with end-users,Yes,Yes,A seperate test set was used to evaluate the AI tool and reported on using appropriate evaluation metrics (eg sensitivity and specificity) ,No,No,No
Xie_2019_Preoperative Differentiation of Uterine Sarcoma from Leiomyoma: Comparison of Three Models Based on Different Segmentation Volumes Using Radiomics,No potential biases were discussed prior to AI development,No relevant attributes of the patient were collected;,Biases were neither investigated nor corrected for,The clinical setting was not reported ,No,This study only used single center data --> no external validation;,"local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, and no intended use and user requirement was described",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has not been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has not been evaluated against real-world data (test data),Explainibility has not been defined at the design phase,Explainability has not been defined or not evaluated with end-users,No,Yes,Evaluation was not conducted using standardized and best practices,No,No,No
Wang_2022_Malignancy risk of gastrointestinal stromal tumors evaluated with noninvasive radiomics: A multi-center study,No potential biases were discussed prior to AI development,"More than two attributes in the list were collected, OR with other attributes",Biases were investigated and reported,The clinical setting was not reported ,Yes,Evaluation was performed using external dataset from multiple sites;,"local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, however intended use and end-user requirement was described; OR, multiple stakeholders were present for AI development, no intented use or requirement was decribed",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has not been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has been evaluated against real-world data (test data),Explainibility has not been defined at the design phase,Explainability has not been defined or not evaluated with end-users,Yes,Yes,The AI tool was compared to current standard practice (ie evaluation metrics on test set should be compared to same metrics for current clinical tests - so for example how did it compare to radiologists),No,No,No
Wang_2023_A radiomics‑clinical combined nomogram‑based on non‑enhanced CT for discriminating the risk stratification in GISTs,No potential biases were discussed prior to AI development,"At least the two attributes in the list collected; (list :sex OR gender, age, ethnicity, risk factors(as 1 item), comorbidities or disabilities)",Biases were investigated and reported,The clinical setting was not reported ,Yes,This study only used single center data --> no external validation;,"local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, however intended use and end-user requirement was described; OR, multiple stakeholders were present for AI development, no intented use or requirement was decribed",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has not been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has not been evaluated against real-world data (test data),Explainibility has not been defined at the design phase,Explainability has not been defined or not evaluated with end-users,Yes,Yes,A seperate test set was used to evaluate the AI tool and reported on using appropriate evaluation metrics (eg sensitivity and specificity) ,No,No,No
Wang_2021_Artificial Intelligence for Classification of Soft-Tissue Masses at US,No potential biases were discussed prior to AI development,"At least the two attributes in the list collected; (list :sex OR gender, age, ethnicity, risk factors(as 1 item), comorbidities or disabilities)",Biases were investigated and reported,"Clinical setting outlined (eg primary healthcare centres, hospitals, home care, low vs high-resource settings, one or multiple countries)",Yes,This study only used single center data --> no external validation;,"local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, however intended use and end-user requirement was described; OR, multiple stakeholders were present for AI development, no intented use or requirement was decribed",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has not been evaluated against real-world data (test data),Explainibility has not been defined at the design phase,Explainability has not been defined or not evaluated with end-users,Yes,Yes,The AI tool was compared to current standard practice (ie evaluation metrics on test set should be compared to same metrics for current clinical tests - so for example how did it compare to radiologists),No,No,No
Vallières_2015_A radiomics model from joint FDG-PET and MRI texture features for the prediction of lung metastases in soft-tissue sarcomas of the extremities,No potential biases were discussed prior to AI development,"More than two attributes in the list were collected, OR with other attributes",Biases were neither investigated nor corrected for,The clinical setting was not reported ,Yes,This study only used single center data --> no external validation;,"local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,Documentation about 1-2 points (see decription) have been provided),No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, however intended use and end-user requirement was described; OR, multiple stakeholders were present for AI development, no intented use or requirement was decribed",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has not been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has not been evaluated against real-world data (test data),Explainibility has not been defined at the design phase,Explainability has not been defined or not evaluated with end-users,Yes,Yes,Evaluation was not conducted using standardized and best practices,No,No,No
Toyohara_2022_Development of a deep learning method for improving diagnostic accuracy for uterine sarcoma cases,No potential biases were discussed prior to AI development,No relevant attributes of the patient were collected;,Biases were neither investigated nor corrected for,The clinical setting was not reported ,Yes,This study only used single center data --> no external validation;,"local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, however intended use and end-user requirement was described; OR, multiple stakeholders were present for AI development, no intented use or requirement was decribed",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has not been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has not been evaluated against real-world data (test data),Explainibility has not been defined at the design phase,Explainability has not been defined or not evaluated with end-users,Yes,Yes,The AI tool was compared to current standard practice (ie evaluation metrics on test set should be compared to same metrics for current clinical tests - so for example how did it compare to radiologists),No,No,No
Sudjai_2023_Robustness of Radiomic Features: Two-Dimensional versus Three-Dimensional MRI-Based Feature Reproducibility in Lipomatous Soft-Tissue Tumors,No potential biases were discussed prior to AI development,"At least the two attributes in the list collected; (list :sex OR gender, age, ethnicity, risk factors(as 1 item), comorbidities or disabilities)",Biases were neither investigated nor corrected for,The clinical setting was not reported ,Yes,This study only used single center data --> no external validation;,"local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, however intended use and end-user requirement was described; OR, multiple stakeholders were present for AI development, no intented use or requirement was decribed",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has not been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has not been evaluated against real-world data (test data),Explainibility has not been defined at the design phase,Explainability has not been defined or not evaluated with end-users,Yes,Yes,A seperate test set was used to evaluate the AI tool and reported on using appropriate evaluation metrics (eg sensitivity and specificity) ,No,No,No
Spraker_2019_MRI Radiomic Features Are Independently Associated With Overall Survival in Soft Tissue Sarcoma,No potential biases were discussed prior to AI development,"More than two attributes in the list were collected, OR with other attributes",Biases were investigated and reported,The clinical setting was not reported ,Yes,"Evaluation was performed using external dataset from one other site (or same source, eg public available);","local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,Monitoring or quality control measures have been implemented for either the inputs or outputs ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, however intended use and end-user requirement was described; OR, multiple stakeholders were present for AI development, no intented use or requirement was decribed",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has not been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has been evaluated against real-world data (test data),"At least one of the following areas is discussed: (i) the goal of the explanations (eg global description of the model’s behaviour vs local explanation of each AI decision), (ii) the most suitable approach for AI explainability and (iii) the potential limitations to anticipate and monitor (eg over-reliance of the end-users on the AI decision)",Explainability has not been defined or not evaluated with end-users,Yes,Yes,A seperate test set was used to evaluate the AI tool and reported on using appropriate evaluation metrics (eg sensitivity and specificity) ,No,No,No
Song_2022_Radiomics Nomogram Based on Contrast-enhanced CT to Predict the Malignant Potential of Gastrointestinal Stromal Tumor: A Two-center Study,No potential biases were discussed prior to AI development,"More than two attributes in the list were collected, OR with other attributes",Biases were investigated and reported,The clinical setting was not reported ,Yes,"Evaluation was performed using external dataset from one other site (or same source, eg public available);","local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, however intended use and end-user requirement was described; OR, multiple stakeholders were present for AI development, no intented use or requirement was decribed",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has not been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has been evaluated against real-world data (test data) and the AI tool's robustness has been optimized (if applicable) using mitigation methods,Explainibility has not been defined at the design phase,Explainability has not been defined or not evaluated with end-users,Yes,Yes,A seperate test set was used to evaluate the AI tool and reported on using appropriate evaluation metrics (eg sensitivity and specificity) ,No,No,No
Malek_2019_A machine learning approach for distinguishing uterine sarcoma from leiomyomas based on perfusion weighted MRI parameters,No potential biases were discussed prior to AI development,"At least the two attributes in the list collected; (list :sex OR gender, age, ethnicity, risk factors(as 1 item), comorbidities or disabilities)",Biases were neither investigated nor corrected for,The clinical setting was not reported ,No,This study only used single center data --> no external validation;,"local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,Monitoring or quality control measures have been implemented for either the inputs or outputs ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, however intended use and end-user requirement was described; OR, multiple stakeholders were present for AI development, no intented use or requirement was decribed",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has not been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has not been evaluated against real-world data (test data),Explainibility has not been defined at the design phase,Explainability has not been defined or not evaluated with end-users,Yes,Yes,Evaluation was not conducted using standardized and best practices,No,No,No
Gawade_2023_Application of the convolutional neural networks and supervised deep-learning methods for osteosarcoma bone cancer detection,No potential biases were discussed prior to AI development,No relevant attributes of the patient were collected;,Biases were neither investigated nor corrected for,The clinical setting was not reported ,No,This study only used single center data --> no external validation;,"local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, and no intended use and user requirement was described",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has not been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has not been evaluated against real-world data (test data),Explainibility has not been defined at the design phase,Explainability has not been defined or not evaluated with end-users,No,No,Evaluation was not conducted using standardized and best practices,No,No,No
Park_2022_Artificial intelligence-based classification of bone tumors in the proximal femur on plain radiographs: System development and validation,No potential biases were discussed prior to AI development,No relevant attributes of the patient were collected;,Biases were neither investigated nor corrected for,The clinical setting was not reported ,Yes,This study only used single center data --> no external validation;,"local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, however intended use and end-user requirement was described; OR, multiple stakeholders were present for AI development, no intented use or requirement was decribed",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has not been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has not been evaluated against real-world data (test data),Explainibility has not been defined at the design phase,Explainability has been evaluated in silico OR with end users involved in the development ,Yes,Yes,The AI tool was compared to current standard practice (ie evaluation metrics on test set should be compared to same metrics for current clinical tests - so for example how did it compare to radiologists),No,No,No
Li_2019_Computer‑aided diagnosis of gastrointestinal stromal tumors: a radiomics method on endoscopic ultrasound image,No potential biases were discussed prior to AI development,"At least the two attributes in the list collected; (list :sex OR gender, age, ethnicity, risk factors(as 1 item), comorbidities or disabilities)",Biases were neither investigated nor corrected for,The clinical setting was not reported ,No,This study only used single center data --> no external validation;,"local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, however intended use and end-user requirement was described; OR, multiple stakeholders were present for AI development, no intented use or requirement was decribed",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has not been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has not been evaluated against real-world data (test data),Explainibility has not been defined at the design phase,Explainability has not been defined or not evaluated with end-users,Yes,Yes,A seperate test set was used to evaluate the AI tool and reported on using appropriate evaluation metrics (eg sensitivity and specificity) ,No,No,No
Peeken_2019_CT-based radiomic features predict tumor grading and have prognostic value in patients with soft tissue sarcomas treated with neoadjuvant radiation therapy,No potential biases were discussed prior to AI development,"More than two attributes in the list were collected, OR with other attributes",Biases were investigated and reported,The clinical setting was not reported ,Yes,Evaluation was performed using external dataset from multiple sites;,"local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, however intended use and end-user requirement was described; OR, multiple stakeholders were present for AI development, no intented use or requirement was decribed",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has not been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has been evaluated against real-world data (test data),Explainibility has not been defined at the design phase,Explainability has not been defined or not evaluated with end-users,Yes,Yes,A seperate test set was used to evaluate the AI tool and reported on using appropriate evaluation metrics (eg sensitivity and specificity) ,No,No,No
Meijun_2023_Radiomics signatures based on contrast‑enhanced CT for preoperative prediction of the Ki‑67 proliferation state in gastrointestinal stromal tumors,No potential biases were discussed prior to AI development,"More than two attributes in the list were collected, OR with other attributes",Biases were neither investigated nor corrected for,The clinical setting was not reported ,Yes,This study only used single center data --> no external validation;,"local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, and no intended use and user requirement was described",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has not been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has not been evaluated against real-world data (test data),Explainibility has not been defined at the design phase,Explainability has not been defined or not evaluated with end-users,No,Yes,Evaluation was not conducted using standardized and best practices,No,No,No
Luo_2022_Radiomics Analysis of Multiparametric MRI for Prediction of Synchronous Lung Metastases in Osteosarcoma,No potential biases were discussed prior to AI development,"More than two attributes in the list were collected, OR with other attributes",Biases were investigated and reported,The clinical setting was not reported ,Yes,This study only used single center data --> no external validation;,"local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, however intended use and end-user requirement was described; OR, multiple stakeholders were present for AI development, no intented use or requirement was decribed",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has not been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has been evaluated against real-world data (test data),Explainibility has not been defined at the design phase,Explainability has not been defined or not evaluated with end-users,Yes,Yes,A seperate test set was used to evaluate the AI tool and reported on using appropriate evaluation metrics (eg sensitivity and specificity) ,No,No,No
Giraudo_2022_Radiomic features as biomarkers of soft tissue paediatric sarcomas: preliminary results of a PET/MR study,No potential biases were discussed prior to AI development,"At least the two attributes in the list collected; (list :sex OR gender, age, ethnicity, risk factors(as 1 item), comorbidities or disabilities)",Biases were neither investigated nor corrected for,The clinical setting was not reported ,Yes,This study only used single center data --> no external validation;,"local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, however intended use and end-user requirement was described; OR, multiple stakeholders were present for AI development, no intented use or requirement was decribed",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has not been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has not been evaluated against real-world data (test data),Explainibility has not been defined at the design phase,Explainability has not been defined or not evaluated with end-users,Yes,Yes,Evaluation was not conducted using standardized and best practices,No,No,No
Longfei_2019_Radiomic analysis of multiparametric magnetic resonance imaging for differentiating skull base chordoma and chondrosarcoma,No potential biases were discussed prior to AI development,"At least the two attributes in the list collected; (list :sex OR gender, age, ethnicity, risk factors(as 1 item), comorbidities or disabilities)",Biases were investigated and reported,The clinical setting was not reported ,Yes,This study only used single center data --> no external validation;,"local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, however intended use and end-user requirement was described; OR, multiple stakeholders were present for AI development, no intented use or requirement was decribed",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has not been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has been evaluated against real-world data (test data),Explainibility has not been defined at the design phase,Explainability has not been defined or not evaluated with end-users,Yes,Yes,A seperate test set was used to evaluate the AI tool and reported on using appropriate evaluation metrics (eg sensitivity and specificity) ,No,No,No
Feng_2022_Prediction of the Ki-67 expression level and prognosis of gastrointestinal stromal tumors based on CT radiomics nomogram,No potential biases were discussed prior to AI development,"More than two attributes in the list were collected, OR with other attributes",Biases were neither investigated nor corrected for,The clinical setting was not reported ,Yes,This study only used single center data --> no external validation;,"local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, however intended use and end-user requirement was described; OR, multiple stakeholders were present for AI development, no intented use or requirement was decribed",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has not been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has not been evaluated against real-world data (test data),Explainibility has not been defined at the design phase,Explainability has not been defined or not evaluated with end-users,Yes,Yes,A seperate test set was used to evaluate the AI tool and reported on using appropriate evaluation metrics (eg sensitivity and specificity) ,No,No,No
Peeken_2021_MRI-based delta-radiomics predicts pathologic complete response in high-grade soft-tissue sarcoma patients treated with neoadjuvant therapy,No potential biases were discussed prior to AI development,"More than two attributes in the list were collected, OR with other attributes",Biases were investigated and reported,The clinical setting was not reported ,Yes,"Evaluation was performed using external dataset from one other site (or same source, eg public available);","local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, however intended use and end-user requirement was described; OR, multiple stakeholders were present for AI development, no intented use or requirement was decribed",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has not been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has been evaluated against real-world data (test data),Explainibility has not been defined at the design phase,Explainability has not been defined or not evaluated with end-users,Yes,Yes,A seperate test set was used to evaluate the AI tool and reported on using appropriate evaluation metrics (eg sensitivity and specificity) ,No,No,No
Gitto_2020_MRI radiomics-based machine-learning classification of bone chondrosarcoma,No potential biases were discussed prior to AI development,"At least the two attributes in the list collected; (list :sex OR gender, age, ethnicity, risk factors(as 1 item), comorbidities or disabilities)",Biases were neither investigated nor corrected for,The clinical setting was not reported ,Yes,This study only used single center data --> no external validation;,"local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, however intended use and end-user requirement was described; OR, multiple stakeholders were present for AI development, no intented use or requirement was decribed",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has not been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has not been evaluated against real-world data (test data),Explainibility has not been defined at the design phase,Explainability has not been defined or not evaluated with end-users,Yes,Yes,The AI tool was compared to current standard practice (ie evaluation metrics on test set should be compared to same metrics for current clinical tests - so for example how did it compare to radiologists),No,No,No
Luo_2023_Prediction of response to preoperative neoadjuvant chemotherapy in extremity high-grade osteosarcoma using X-ray and multiparametric MRI radiomics,No potential biases were discussed prior to AI development,"More than two attributes in the list were collected, OR with other attributes",Biases were neither investigated nor corrected for,The clinical setting was not reported ,Yes,This study only used single center data --> no external validation;,"local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, however intended use and end-user requirement was described; OR, multiple stakeholders were present for AI development, no intented use or requirement was decribed",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has not been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has not been evaluated against real-world data (test data),Explainibility has not been defined at the design phase,Explainability has not been defined or not evaluated with end-users,Yes,Yes,Evaluation was not conducted using standardized and best practices,No,No,No
Kim_2021_Prediction of Neoadjuvant Chemotherapy Response in Osteosarcoma Using Convolutional Neural Network of Tumor Center 18F-FDG PET Images,No potential biases were discussed prior to AI development,"More than two attributes in the list were collected, OR with other attributes",Biases were neither investigated nor corrected for,The clinical setting was not reported ,No,This study only used single center data --> no external validation;,"local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, however intended use and end-user requirement was described; OR, multiple stakeholders were present for AI development, no intented use or requirement was decribed",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has not been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has not been evaluated against real-world data (test data),Explainibility has not been defined at the design phase,Explainability has not been defined or not evaluated with end-users,Yes,Yes,Evaluation was not conducted using standardized and best practices,No,No,No
Jeong_2019_Prediction of Chemotherapy Response of Osteosarcoma Using Baseline 18F-FDG Textural Features Machine Learning Approaches with PCA,No potential biases were discussed prior to AI development,No relevant attributes of the patient were collected;,Biases were neither investigated nor corrected for,The clinical setting was not reported ,Yes,This study only used single center data --> no external validation;,"local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, however intended use and end-user requirement was described; OR, multiple stakeholders were present for AI development, no intented use or requirement was decribed",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has not been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has not been evaluated against real-world data (test data),Explainibility has not been defined at the design phase,Explainability has not been defined or not evaluated with end-users,Yes,Yes,Evaluation was not conducted using standardized and best practices,No,No,No
Nakagawa_2023_Performance of Machine Learning Methods Based on Multi-Sequence Textural Parameters Using Magnetic Resonance Imaging and Clinical Information to Differentiate Malignant and Benign Soft Tissue Tumors,No potential biases were discussed prior to AI development,"At least the two attributes in the list collected; (list :sex OR gender, age, ethnicity, risk factors(as 1 item), comorbidities or disabilities)",Biases were neither investigated nor corrected for,The clinical setting was not reported ,Yes,This study only used single center data --> no external validation;,"local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, however intended use and end-user requirement was described; OR, multiple stakeholders were present for AI development, no intented use or requirement was decribed",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has not been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has not been evaluated against real-world data (test data),Explainibility has not been defined at the design phase,Explainability has not been defined or not evaluated with end-users,Yes,Yes,The AI tool was compared to current standard practice (ie evaluation metrics on test set should be compared to same metrics for current clinical tests - so for example how did it compare to radiologists),No,No,No
Juntu_2010_Machine Learning Study of Several Classifiers Trained With Texture Analysis Features to Differentiate Benign from Malignant Soft-Tissue Tumors in T1-MRI Images,"Potential biases in at least 1 group (group attributes, medical profile, human biases) were discussed prior to AI development",No relevant attributes of the patient were collected;,Biases were neither investigated nor corrected for,The clinical setting was not reported ,Yes,This study only used single center data --> no external validation;,"local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, and no intended use and user requirement was described",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has not been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has not been evaluated against real-world data (test data),Explainibility has not been defined at the design phase,Explainability has not been defined or not evaluated with end-users,No,No,The AI tool was compared to current standard practice (ie evaluation metrics on test set should be compared to same metrics for current clinical tests - so for example how did it compare to radiologists),No,No,No
Nakagawa_2019_Machine Learning to Differentiate T2-Weighted Hyperintense Uterine Leiomyomas from Uterine Sarcomas by Utilizing Multiparametric Magnetic Resonance Quantitative Imaging Features,No potential biases were discussed prior to AI development,"More than two attributes in the list were collected, OR with other attributes",Biases were neither investigated nor corrected for,The clinical setting was not reported ,Yes,This study only used single center data --> no external validation;,"local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, and no intended use and user requirement was described",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has not been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has not been evaluated against real-world data (test data),Explainibility has not been defined at the design phase,Explainability has not been defined or not evaluated with end-users,No,Yes,The AI tool was compared to current standard practice (ie evaluation metrics on test set should be compared to same metrics for current clinical tests - so for example how did it compare to radiologists),No,No,No
Gao_2021_Prediction of soft tissue sarcoma response to radiotherapy using longitudinal diffusion MRI and a deep neural network with generative adversarial networkbased data augmentation,No potential biases were discussed prior to AI development,"More than two attributes in the list were collected, OR with other attributes",Biases were neither investigated nor corrected for,The clinical setting was not reported ,Yes,This study only used single center data --> no external validation;,"local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,Monitoring or quality control measures have been implemented for either the inputs or outputs ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, however intended use and end-user requirement was described; OR, multiple stakeholders were present for AI development, no intented use or requirement was decribed",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has not been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has not been evaluated against real-world data (test data),Explainibility has not been defined at the design phase,Explainability has not been defined or not evaluated with end-users,Yes,Yes,A seperate test set was used to evaluate the AI tool and reported on using appropriate evaluation metrics (eg sensitivity and specificity) ,No,No,No
Farhidzadeh_2016_A Quantitative Histogram-based Approach to Predict Treatment Outcome for Soft Tissue Sarcomas Using Pre- and Post-treatment MRIs,No potential biases were discussed prior to AI development,No relevant attributes of the patient were collected;,Biases were neither investigated nor corrected for,The clinical setting was not reported ,No,This study only used single center data --> no external validation;,"local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, however intended use and end-user requirement was described; OR, multiple stakeholders were present for AI development, no intented use or requirement was decribed",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has not been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has not been evaluated against real-world data (test data),Explainibility has not been defined at the design phase,Explainability has not been defined or not evaluated with end-users,Yes,No,Evaluation was not conducted using standardized and best practices,No,No,No
Kumar_2016_Classification of Benign and Malignant bone lesions on CT ImagesUsing Support Vector Machine: A Comparison of Kernel Functions,No potential biases were discussed prior to AI development,No relevant attributes of the patient were collected;,Biases were neither investigated nor corrected for,The clinical setting was not reported ,No,This study only used single center data --> no external validation;,"local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, and no intended use and user requirement was described",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has not been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has not been evaluated against real-world data (test data),Explainibility has not been defined at the design phase,Explainability has not been defined or not evaluated with end-users,No,No,Evaluation was not conducted using standardized and best practices,No,No,No
Ning_2019_Pattern Classification for Gastrointestinal Stromal Tumors by Integration of Radiomics and Deep Convolutional Features,No potential biases were discussed prior to AI development,No relevant attributes of the patient were collected;,Biases were neither investigated nor corrected for,The clinical setting was not reported ,Yes,This study only used single center data --> no external validation;,"local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, however intended use and end-user requirement was described; OR, multiple stakeholders were present for AI development, no intented use or requirement was decribed",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has not been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has not been evaluated against real-world data (test data),Explainibility has not been defined at the design phase,Explainability has not been defined or not evaluated with end-users,Yes,Yes,A seperate test set was used to evaluate the AI tool and reported on using appropriate evaluation metrics (eg sensitivity and specificity) ,No,No,No
Peng_2019_Deep multi-modality collaborative learning for distant metastases predication in PET-CT soft-tissue sarcoma studies,No potential biases were discussed prior to AI development,No relevant attributes of the patient were collected;,Biases were neither investigated nor corrected for,The clinical setting was not reported ,Yes,This study only used single center data --> no external validation;,"local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, however intended use and end-user requirement was described; OR, multiple stakeholders were present for AI development, no intented use or requirement was decribed",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has not been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has not been evaluated against real-world data (test data),Explainibility has not been defined at the design phase,Explainability has not been defined or not evaluated with end-users,Yes,No,Evaluation was not conducted using standardized and best practices,No,No,No
Shen_2018_Osteosarcoma Patients Classification Using Plain X-Rays and Metabolomic Data,No potential biases were discussed prior to AI development,No relevant attributes of the patient were collected;,Biases were neither investigated nor corrected for,The clinical setting was not reported ,Yes,This study only used single center data --> no external validation;,"local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, however intended use and end-user requirement was described; OR, multiple stakeholders were present for AI development, no intented use or requirement was decribed",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has not been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has not been evaluated against real-world data (test data),Explainibility has not been defined at the design phase,Explainability has not been defined or not evaluated with end-users,Yes,No,A seperate test set was used to evaluate the AI tool and reported on using appropriate evaluation metrics (eg sensitivity and specificity) ,No,No,No
Grueneisen_2019_18F-FDG PET/MRI for Therapy Response Assessment of Isolated Limb Perfusion in Patients with Soft-Tissue Sarcomas,No potential biases were discussed prior to AI development,No relevant attributes of the patient were collected;,Biases were neither investigated nor corrected for,The clinical setting was not reported ,No,This study only used single center data --> no external validation;,"local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, however intended use and end-user requirement was described; OR, multiple stakeholders were present for AI development, no intented use or requirement was decribed",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has not been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has not been evaluated against real-world data (test data),Explainibility has not been defined at the design phase,Explainability has not been defined or not evaluated with end-users,Yes,Yes,The AI tool was compared to current standard practice (ie evaluation metrics on test set should be compared to same metrics for current clinical tests - so for example how did it compare to radiologists),No,No,No
Cao_2023_Differentiation of retroperitoneal paragangliomas and schwannomas based on computed tomography radiomics,No potential biases were discussed prior to AI development,"More than two attributes in the list were collected, OR with other attributes",Biases were investigated and reported,The clinical setting was not reported ,Yes,"Evaluation was performed using external dataset from one other site (or same source, eg public available);","local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, however intended use and end-user requirement was described; OR, multiple stakeholders were present for AI development, no intented use or requirement was decribed",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has not been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has been evaluated against real-world data (test data),Explainibility has not been defined at the design phase,Explainability has not been defined or not evaluated with end-users,Yes,Yes,A seperate test set was used to evaluate the AI tool and reported on using appropriate evaluation metrics (eg sensitivity and specificity) ,No,No,No
Corino-2017-Radiomic analysis of soft tissues sarcomas can distinguish intermediate from,No potential biases were discussed prior to AI development,"More than two attributes in the list were collected, OR with other attributes",Biases were neither investigated nor corrected for,The clinical setting was not reported ,Yes,This study only used single center data --> no external validation;,"local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, however intended use and end-user requirement was described; OR, multiple stakeholders were present for AI development, no intented use or requirement was decribed",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has been evaluated against real-world data (test data),Explainibility has not been defined at the design phase,Explainability has not been defined or not evaluated with end-users,Yes,Yes,A seperate test set was used to evaluate the AI tool and reported on using appropriate evaluation metrics (eg sensitivity and specificity) ,No,No,No
Cao_2023_Machine learning-based radiomics analysis for predicting local recurrence of primary dermatofibrosarcoma protuberans after surgical treatment,No potential biases were discussed prior to AI development,"More than two attributes in the list were collected, OR with other attributes","Biases were also corrected for by mitigation measures (In case of no biases found, 3 also applies)",The clinical setting was not reported ,Yes,"Evaluation was performed using external dataset from one other site (or same source, eg public available);","local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, however intended use and end-user requirement was described; OR, multiple stakeholders were present for AI development, no intented use or requirement was decribed",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has not been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has been evaluated against real-world data (test data),Explainibility has not been defined at the design phase,Explainability has not been defined or not evaluated with end-users,Yes,Yes,A seperate test set was used to evaluate the AI tool and reported on using appropriate evaluation metrics (eg sensitivity and specificity) ,No,No,No
Chen-2020-Development and external validation of an MRI-based radiomics nomogram for pretreatment prediction for early relapse,No potential biases were discussed prior to AI development,"More than two attributes in the list were collected, OR with other attributes",Biases were investigated and reported,The clinical setting was not reported ,Yes,Evaluation was performed using external dataset from multiple sites;,local clinical validity has been discussed and evaluated,Risks regarding the AI lifecycle have not been described,No documentation has been provided,No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, however intended use and end-user requirement was described; OR, multiple stakeholders were present for AI development, no intented use or requirement was decribed",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has been evaluated against real-world data (test data),Explainibility has not been defined at the design phase,Explainability has not been defined or not evaluated with end-users,Yes,Yes,A seperate test set was used to evaluate the AI tool and reported on using appropriate evaluation metrics (eg sensitivity and specificity) ,No,No,No
Altameen_2020,No potential biases were discussed prior to AI development,No relevant attributes of the patient were collected;,Biases were neither investigated nor corrected for,The clinical setting was not reported ,No,This study only used single center data --> no external validation;,"local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, and no intended use and user requirement was described",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has not been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has not been evaluated against real-world data (test data),Explainibility has not been defined at the design phase,Explainability has not been defined or not evaluated with end-users,No,No,Evaluation was not conducted using standardized and best practices,No,No,No
Chiappa-2021-Using rADioMIcs and machine learning with ultrasonography for the differential diagnosis of myometRiAL tumors,No potential biases were discussed prior to AI development,"More than two attributes in the list were collected, OR with other attributes",Biases were investigated and reported,The clinical setting was not reported ,Yes,This study only used single center data --> no external validation;,"local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, however intended use and end-user requirement was described; OR, multiple stakeholders were present for AI development, no intented use or requirement was decribed",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has not been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has not been evaluated against real-world data (test data),Explainibility has not been defined at the design phase,Explainability has not been defined or not evaluated with end-users,Yes,Yes,Evaluation was not conducted using standardized and best practices,No,No,No
Bandyopadhyay_2019,No potential biases were discussed prior to AI development,No relevant attributes of the patient were collected;,Biases were neither investigated nor corrected for,The clinical setting was not reported ,No,This study only used single center data --> no external validation;,"local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,Monitoring or quality control measures have been implemented for either the inputs or outputs ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, and no intended use and user requirement was described",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has not been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has not been evaluated against real-world data (test data),Explainibility has not been defined at the design phase,Explainability has not been defined or not evaluated with end-users,Yes,No,Evaluation was not conducted using standardized and best practices,No,No,No
Chen-2019-Developed and validated a prognostic nomogram for recurrence-free survival after complete surgical resection of local primary gastrointestinal stromal tumors based on deep learning,No potential biases were discussed prior to AI development,"More than two attributes in the list were collected, OR with other attributes",Biases were investigated and reported,The clinical setting was not reported ,Yes,"Evaluation was performed using external dataset from one other site (or same source, eg public available);","local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, however intended use and end-user requirement was described; OR, multiple stakeholders were present for AI development, no intented use or requirement was decribed",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has not been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has been evaluated against real-world data (test data),Explainibility has not been defined at the design phase,Explainability has not been defined or not evaluated with end-users,Yes,Yes,A seperate test set was used to evaluate the AI tool and reported on using appropriate evaluation metrics (eg sensitivity and specificity) ,No,No,No
Ssalamah_2013,"Potential biases in at least 1 group (group attributes, medical profile, human biases) were discussed prior to AI development","At least the two attributes in the list collected; (list :sex OR gender, age, ethnicity, risk factors(as 1 item), comorbidities or disabilities)",Biases were neither investigated nor corrected for,The clinical setting was not reported ,Yes,This study only used single center data --> no external validation;,"local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, and no intended use and user requirement was described",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has not been evaluated against real-world data (test data),Explainibility has not been defined at the design phase,Explainability has not been defined or not evaluated with end-users,No,No,Evaluation was not conducted using standardized and best practices,No,No,No
Crombé-2018-T2‐based MRI Delta‐radiomics improve response prediction in soft‐tissue,No potential biases were discussed prior to AI development,"More than two attributes in the list were collected, OR with other attributes",Biases were investigated and reported,The clinical setting was not reported ,Yes,This study only used single center data --> no external validation;,"local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, however intended use and end-user requirement was described; OR, multiple stakeholders were present for AI development, no intented use or requirement was decribed",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has not been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has been evaluated against real-world data (test data),Explainibility has not been defined at the design phase,Explainability has not been defined or not evaluated with end-users,Yes,Yes,A seperate test set was used to evaluate the AI tool and reported on using appropriate evaluation metrics (eg sensitivity and specificity) ,No,No,No
Chen-2021-MRI-based radiomics signature for pr,No potential biases were discussed prior to AI development,"More than two attributes in the list were collected, OR with other attributes",Biases were investigated and reported,The clinical setting was not reported ,Yes,Evaluation was performed using external dataset from multiple sites;,"local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, however intended use and end-user requirement was described; OR, multiple stakeholders were present for AI development, no intented use or requirement was decribed",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has been evaluated against real-world data (test data),Explainibility has not been defined at the design phase,Explainability has been evaluated in silico OR with end users involved in the development ,Yes,Yes,A seperate test set was used to evaluate the AI tool and reported on using appropriate evaluation metrics (eg sensitivity and specificity) ,No,No,No
Chen-2020-CT-Based Radiomics to Differentiate,No potential biases were discussed prior to AI development,"More than two attributes in the list were collected, OR with other attributes",Biases were investigated and reported,The clinical setting was not reported ,Yes,This study only used single center data --> no external validation;,"local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, however intended use and end-user requirement was described; OR, multiple stakeholders were present for AI development, no intented use or requirement was decribed",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has not been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has not been evaluated against real-world data (test data),Explainibility has not been defined at the design phase,Explainability has not been defined or not evaluated with end-users,Yes,Yes,A seperate test set was used to evaluate the AI tool and reported on using appropriate evaluation metrics (eg sensitivity and specificity) ,No,No,No
Bouhamama_2022,No potential biases were discussed prior to AI development,"More than two attributes in the list were collected, OR with other attributes","Biases were also corrected for by mitigation measures (In case of no biases found, 3 also applies)",The clinical setting was not reported ,Yes,Evaluation was performed using external dataset from multiple sites;,"local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, however intended use and end-user requirement was described; OR, multiple stakeholders were present for AI development, no intented use or requirement was decribed",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has been evaluated against real-world data (test data) and the AI tool's robustness has been optimized (if applicable) using mitigation methods,Explainibility has not been defined at the design phase,Explainability has not been defined or not evaluated with end-users,Yes,Yes,A seperate test set was used to evaluate the AI tool and reported on using appropriate evaluation metrics (eg sensitivity and specificity) ,No,No,No
Chen-2009-Computer-aided diagnosis of soft-tissue tumors using sonographic morphologic and texture features,No potential biases were discussed prior to AI development,"At least the two attributes in the list collected; (list :sex OR gender, age, ethnicity, risk factors(as 1 item), comorbidities or disabilities)",Biases were neither investigated nor corrected for,The clinical setting was not reported ,No,This study only used single center data --> no external validation;,"local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, however intended use and end-user requirement was described; OR, multiple stakeholders were present for AI development, no intented use or requirement was decribed",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has not been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has not been evaluated against real-world data (test data),Explainibility has not been defined at the design phase,Explainability has not been defined or not evaluated with end-users,Yes,Yes,Evaluation was not conducted using standardized and best practices,No,No,No
Chen-2019-Radiomics nomogram for predicting th,No potential biases were discussed prior to AI development,"More than two attributes in the list were collected, OR with other attributes",Biases were neither investigated nor corrected for,The clinical setting was not reported ,Yes,"Evaluation was performed using external dataset from one other site (or same source, eg public available);","local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, however intended use and end-user requirement was described; OR, multiple stakeholders were present for AI development, no intented use or requirement was decribed",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has not been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has been evaluated against real-world data (test data),Explainibility has not been defined at the design phase,Explainability has not been defined or not evaluated with end-users,Yes,Yes,A seperate test set was used to evaluate the AI tool and reported on using appropriate evaluation metrics (eg sensitivity and specificity) ,No,No,No
Chu-2021-Value of radiomics model based on enh,No potential biases were discussed prior to AI development,"More than two attributes in the list were collected, OR with other attributes",Biases were investigated and reported,The clinical setting was not reported ,Yes,This study only used single center data --> no external validation;,"local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, however intended use and end-user requirement was described; OR, multiple stakeholders were present for AI development, no intented use or requirement was decribed",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has not been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has been evaluated against real-world data (test data),Explainibility has not been defined at the design phase,Explainability has not been defined or not evaluated with end-users,Yes,Yes,A seperate test set was used to evaluate the AI tool and reported on using appropriate evaluation metrics (eg sensitivity and specificity) ,No,No,No
Ao_2021,No potential biases were discussed prior to AI development,"More than two attributes in the list were collected, OR with other attributes",Biases were investigated and reported,The clinical setting was not reported ,Yes,This study only used single center data --> no external validation;,"local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, and no intended use and user requirement was described",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has been evaluated against real-world data (test data),Explainibility has not been defined at the design phase,Explainability has not been defined or not evaluated with end-users,Yes,Yes,A seperate test set was used to evaluate the AI tool and reported on using appropriate evaluation metrics (eg sensitivity and specificity) ,No,No,No
Chen-2021-CT Radiomics Model for Discriminating the Risk Stratification of Gastrointestinal Stromal Tumors,No potential biases were discussed prior to AI development,"More than two attributes in the list were collected, OR with other attributes","Biases were also corrected for by mitigation measures (In case of no biases found, 3 also applies)",The clinical setting was not reported ,Yes,Evaluation was performed using external dataset from multiple sites;,"local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, however intended use and end-user requirement was described; OR, multiple stakeholders were present for AI development, no intented use or requirement was decribed",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has been evaluated against real-world data (test data),Explainibility has not been defined at the design phase,Explainability has not been defined or not evaluated with end-users,Yes,Yes,A seperate test set was used to evaluate the AI tool and reported on using appropriate evaluation metrics (eg sensitivity and specificity) ,No,No,No
Banerjee_2018,No potential biases were discussed prior to AI development,"At least the two attributes in the list collected; (list :sex OR gender, age, ethnicity, risk factors(as 1 item), comorbidities or disabilities)",Biases were neither investigated nor corrected for,The clinical setting was not reported ,No,This study only used single center data --> no external validation;,"local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, and no intended use and user requirement was described",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has not been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has not been evaluated against real-world data (test data),Explainibility has not been defined at the design phase,Explainability has not been defined or not evaluated with end-users,No,Yes,Evaluation was not conducted using standardized and best practices,No,No,No
Baskaran_2018,No potential biases were discussed prior to AI development,"More than two attributes in the list were collected, OR with other attributes",Biases were neither investigated nor corrected for,The clinical setting was not reported ,No,This study only used single center data --> no external validation;,"local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, and no intended use and user requirement was described",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has not been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has not been evaluated against real-world data (test data),Explainibility has not been defined at the design phase,Explainability has not been defined or not evaluated with end-users,Yes,Yes,Evaluation was not conducted using standardized and best practices,No,No,No
Chen-2021-Radiomics Analysis of Fat Saturated T2-Weighted MRI Sequences for Prognostic Prediction to Soft-Tissue Sarcoma of the Extremities and Trunk Treated With Neoadjuvant Radiotherapy,No potential biases were discussed prior to AI development,"More than two attributes in the list were collected, OR with other attributes",Biases were investigated and reported,The clinical setting was not reported ,Yes,This study only used single center data --> no external validation;,"local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, and no intended use and user requirement was described",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has not been evaluated against real-world data (test data),Explainibility has not been defined at the design phase,Explainability has not been defined or not evaluated with end-users,No,No,Evaluation was not conducted using standardized and best practices,No,No,No
Cilengir-2023-The diagnostic value of magnetic,No potential biases were discussed prior to AI development,"At least the two attributes in the list collected; (list :sex OR gender, age, ethnicity, risk factors(as 1 item), comorbidities or disabilities)",Biases were investigated and reported,The clinical setting was not reported ,Yes,This study only used single center data --> no external validation;,"local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, however intended use and end-user requirement was described; OR, multiple stakeholders were present for AI development, no intented use or requirement was decribed",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has not been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has been evaluated against real-world data (test data),Explainibility has not been defined at the design phase,Explainability has not been defined or not evaluated with end-users,Yes,Yes,A seperate test set was used to evaluate the AI tool and reported on using appropriate evaluation metrics (eg sensitivity and specificity) ,No,No,No
Chiou-2009-Computer-aided diagnosis of peripheral soft tissue masses based on ultrasound imaging,No potential biases were discussed prior to AI development,No relevant attributes of the patient were collected;,Biases were neither investigated nor corrected for,The clinical setting was not reported ,No,This study only used single center data --> no external validation;,"local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, however intended use and end-user requirement was described; OR, multiple stakeholders were present for AI development, no intented use or requirement was decribed",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has not been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has not been evaluated against real-world data (test data),Explainibility has not been defined at the design phase,Explainability has not been defined or not evaluated with end-users,Yes,Yes,Evaluation was not conducted using standardized and best practices,No,No,No
Crombé-2020-High‐Grade Soft‐Tissue Sarcomas  Can Optimizing Dynamic Contrast‐Enhanced MRI,No potential biases were discussed prior to AI development,"More than two attributes in the list were collected, OR with other attributes",Biases were neither investigated nor corrected for,The clinical setting was not reported ,Yes,This study only used single center data --> no external validation;,"local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, however intended use and end-user requirement was described; OR, multiple stakeholders were present for AI development, no intented use or requirement was decribed",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,"Extensive reporting, including reference to the literature and other primary sources, about how the data may vary (or does not vary) to the real world data",The representative of the training data to the real-world data was not evaluated,The AI tool has not been evaluated against real-world data (test data),Explainibility has not been defined at the design phase,Explainability has not been defined or not evaluated with end-users,Yes,Yes,Evaluation was not conducted using standardized and best practices,No,No,No
Alge_2020,No potential biases were discussed prior to AI development,"At least the two attributes in the list collected; (list :sex OR gender, age, ethnicity, risk factors(as 1 item), comorbidities or disabilities)",Biases were neither investigated nor corrected for,The clinical setting was not reported ,No,This study only used single center data --> no external validation;,"local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, however intended use and end-user requirement was described; OR, multiple stakeholders were present for AI development, no intented use or requirement was decribed",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has not been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has not been evaluated against real-world data (test data),Explainibility has not been defined at the design phase,Explainability has not been defined or not evaluated with end-users,Yes,Yes,Evaluation was not conducted using standardized and best practices,No,No,No
Consalvo-2022-Two-Phase Deep Learning Algorith,"Potential biases in at least 1 group (group attributes, medical profile, human biases) were discussed prior to AI development","At least the two attributes in the list collected; (list :sex OR gender, age, ethnicity, risk factors(as 1 item), comorbidities or disabilities)",Biases were neither investigated nor corrected for,The clinical setting was not reported ,Yes,This study only used single center data --> no external validation;,"local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,Documentation about 1-2 points (see decription) have been provided),Monitoring or quality control measures have been implemented for either the inputs or outputs ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, however intended use and end-user requirement was described; OR, multiple stakeholders were present for AI development, no intented use or requirement was decribed",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has not been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has been evaluated against real-world data (test data),"At least one of the following areas is discussed: (i) the goal of the explanations (eg global description of the model’s behaviour vs local explanation of each AI decision), (ii) the most suitable approach for AI explainability and (iii) the potential limitations to anticipate and monitor (eg over-reliance of the end-users on the AI decision)",Explainability has been evaluated in silico OR with end users involved in the development ,Yes,Yes,A seperate test set was used to evaluate the AI tool and reported on using appropriate evaluation metrics (eg sensitivity and specificity) ,No,No,No
Cappello_2023_A mutation-based radiomics signature predicts response to imatinib in Gastrointestinal Stromal Tumors (GIST),No potential biases were discussed prior to AI development,"More than two attributes in the list were collected, OR with other attributes",Biases were investigated and reported,The clinical setting was not reported ,Yes,"Evaluation was performed using external dataset from one other site (or same source, eg public available);","local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, however intended use and end-user requirement was described; OR, multiple stakeholders were present for AI development, no intented use or requirement was decribed",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has not been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has been evaluated against real-world data (test data),Explainibility has not been defined at the design phase,Explainability has not been defined or not evaluated with end-users,Yes,Yes,A seperate test set was used to evaluate the AI tool and reported on using appropriate evaluation metrics (eg sensitivity and specificity) ,No,No,No
Blackledge_2019,No potential biases were discussed prior to AI development,"At least the two attributes in the list collected; (list :sex OR gender, age, ethnicity, risk factors(as 1 item), comorbidities or disabilities)",Biases were neither investigated nor corrected for,The clinical setting was not reported ,No,This study only used single center data --> no external validation;,"local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, however intended use and end-user requirement was described; OR, multiple stakeholders were present for AI development, no intented use or requirement was decribed",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has not been evaluated against real-world data (test data),Explainibility has not been defined at the design phase,Explainability has not been defined or not evaluated with end-users,Yes,Yes,A seperate test set was used to evaluate the AI tool and reported on using appropriate evaluation metrics (eg sensitivity and specificity) ,No,No,No
Cay-2022-Discrimination of lipoma from atypica,No potential biases were discussed prior to AI development,"More than two attributes in the list were collected, OR with other attributes",Biases were investigated and reported,The clinical setting was not reported ,Yes,This study only used single center data --> no external validation;,"local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, however intended use and end-user requirement was described; OR, multiple stakeholders were present for AI development, no intented use or requirement was decribed",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has not been evaluated against real-world data (test data),Explainibility has not been defined at the design phase,Explainability has not been defined or not evaluated with end-users,Yes,Yes,Evaluation was not conducted using standardized and best practices,No,No,No
Chianca-2021-Radiomic Machine Learning Classifiers in Spine Bone Tumors,No potential biases were discussed prior to AI development,"At least the two attributes in the list collected; (list :sex OR gender, age, ethnicity, risk factors(as 1 item), comorbidities or disabilities)",Biases were neither investigated nor corrected for,The clinical setting was not reported ,Yes,"Evaluation was performed using external dataset from one other site (or same source, eg public available);","local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, however intended use and end-user requirement was described; OR, multiple stakeholders were present for AI development, no intented use or requirement was decribed",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has been evaluated against real-world data (test data),Explainibility has not been defined at the design phase,Explainability has not been defined or not evaluated with end-users,Yes,Yes,The AI tool was compared to current standard practice (ie evaluation metrics on test set should be compared to same metrics for current clinical tests - so for example how did it compare to radiologists),No,No,No
Escobar_2021_Voxel_Wise_Supervsided_Analysis_Of_Tumours,No potential biases were discussed prior to AI development,No relevant attributes of the patient were collected;,Biases were neither investigated nor corrected for,The clinical setting was not reported ,Yes,This study only used single center data --> no external validation;,"local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,Monitoring or quality control measures have been implemented for either the inputs or outputs ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, however intended use and end-user requirement was described; OR, multiple stakeholders were present for AI development, no intented use or requirement was decribed",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has not been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has not been evaluated against real-world data (test data),more than one of the areas has been identified and discussed ,Explainability has been evaluated in silico OR with end users involved in the development ,Yes,No,Evaluation was not conducted using standardized and best practices,No,No,No
Yan_2018_evaluation_of_clinical_plus_imaging_features_and,No potential biases were discussed prior to AI development,"More than two attributes in the list were collected, OR with other attributes",Biases were investigated and reported,The clinical setting was not reported ,No,This study only used single center data --> no external validation;,"local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, however intended use and end-user requirement was described; OR, multiple stakeholders were present for AI development, no intented use or requirement was decribed",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has not been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has not been evaluated against real-world data (test data),Explainibility has not been defined at the design phase,Explainability has not been defined or not evaluated with end-users,Yes,Yes,Evaluation was not conducted using standardized and best practices,No,No,No
Nie_2023_a_computed_tomography_radiomics_nomogram_in,No potential biases were discussed prior to AI development,"More than two attributes in the list were collected, OR with other attributes",Biases were investigated and reported,The clinical setting was not reported ,Yes,"Evaluation was performed using external dataset from one other site (or same source, eg public available);","local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, however intended use and end-user requirement was described; OR, multiple stakeholders were present for AI development, no intented use or requirement was decribed",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has not been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has been evaluated against real-world data (test data),Explainibility has not been defined at the design phase,Explainability has not been defined or not evaluated with end-users,Yes,Yes,A seperate test set was used to evaluate the AI tool and reported on using appropriate evaluation metrics (eg sensitivity and specificity) ,No,No,No
Nguyen_2010_Digital Image Analysis Is a Useful Adjunct to Endoscopic Ultrasonographic,"Potential biases in at least 1 group (group attributes, medical profile, human biases) were discussed prior to AI development",No relevant attributes of the patient were collected;,Biases were neither investigated nor corrected for,The clinical setting was not reported ,No,This study only used single center data --> no external validation;,"local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, however intended use and end-user requirement was described; OR, multiple stakeholders were present for AI development, no intented use or requirement was decribed",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has not been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has been evaluated against real-world data (test data),Explainibility has not been defined at the design phase,Explainability has not been defined or not evaluated with end-users,Yes,Yes,A seperate test set was used to evaluate the AI tool and reported on using appropriate evaluation metrics (eg sensitivity and specificity) ,No,No,No
Kim_2018_Development_of_deep_learning_model_for_prediction_of_chemotherapy_response_using_PET_images_and_radiomics_features,No potential biases were discussed prior to AI development,No relevant attributes of the patient were collected;,Biases were neither investigated nor corrected for,The clinical setting was not reported ,No,This study only used single center data --> no external validation;,"local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, and no intended use and user requirement was described",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has not been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has not been evaluated against real-world data (test data),Explainibility has not been defined at the design phase,Explainability has not been defined or not evaluated with end-users,No,No,Evaluation was not conducted using standardized and best practices,No,No,No
Zhou_2022_Prediction_using_T2-weighted_MRI-based_radiomics,No potential biases were discussed prior to AI development,"More than two attributes in the list were collected, OR with other attributes",Biases were neither investigated nor corrected for,"Clinical setting outlined (eg primary healthcare centres, hospitals, home care, low vs high-resource settings, one or multiple countries)",Yes,"Evaluation was performed using external dataset from one other site (or same source, eg public available);","local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, however intended use and end-user requirement was described; OR, multiple stakeholders were present for AI development, no intented use or requirement was decribed",No,The AI tool was not evaluated for user experience,The AI tool was evaluated for clinical utility and safety,Data acquisiton and possible variation of the data source to the real world has not been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has been evaluated against real-world data (test data),Explainibility has not been defined at the design phase,Explainability has not been defined or not evaluated with end-users,Yes,Yes,A seperate test set was used to evaluate the AI tool and reported on using appropriate evaluation metrics (eg sensitivity and specificity) ,No,No,No
Zhong_2022_Automated_prediction_of_the_neoadjuvant_chemo_response,"Potential biases in at least 1 group (group attributes, medical profile, human biases) were discussed prior to AI development","More than two attributes in the list were collected, OR with other attributes","Biases were also corrected for by mitigation measures (In case of no biases found, 3 also applies)",The clinical setting was not reported ,Yes,This study only used single center data --> no external validation;,"local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, however intended use and end-user requirement was described; OR, multiple stakeholders were present for AI development, no intented use or requirement was decribed",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has been evaluated against real-world data (test data),Explainibility has not been defined at the design phase,Explainability has not been defined or not evaluated with end-users,Yes,Yes,A seperate test set was used to evaluate the AI tool and reported on using appropriate evaluation metrics (eg sensitivity and specificity) ,No,No,No
Zheng_2021_Nonenhanced_MRI-based_radiomics_model_for_preoperative_prediction,No potential biases were discussed prior to AI development,"More than two attributes in the list were collected, OR with other attributes",Biases were investigated and reported,The clinical setting was not reported ,Yes,This study only used single center data --> no external validation;,"local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, however intended use and end-user requirement was described; OR, multiple stakeholders were present for AI development, no intented use or requirement was decribed",No,The AI tool was not evaluated for user experience,The AI tool was evaluated for clinical utility and safety,Data acquisiton and possible variation of the data source to the real world has not been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has been evaluated against real-world data (test data),Explainibility has not been defined at the design phase,Explainability has not been defined or not evaluated with end-users,Yes,Yes,A seperate test set was used to evaluate the AI tool and reported on using appropriate evaluation metrics (eg sensitivity and specificity) ,No,No,No
Zheng_2021_Prediction_of_Clinical_Outcome,No potential biases were discussed prior to AI development,"More than two attributes in the list were collected, OR with other attributes","Biases were also corrected for by mitigation measures (In case of no biases found, 3 also applies)",The clinical setting was not reported ,Yes,This study only used single center data --> no external validation;,"local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, however intended use and end-user requirement was described; OR, multiple stakeholders were present for AI development, no intented use or requirement was decribed",No,The AI tool was not evaluated for user experience,The AI tool was evaluated for clinical utility and safety,Data acquisiton and possible variation of the data source to the real world has not been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has been evaluated against real-world data (test data),Explainibility has not been defined at the design phase,Explainability has not been defined or not evaluated with end-users,Yes,Yes,A seperate test set was used to evaluate the AI tool and reported on using appropriate evaluation metrics (eg sensitivity and specificity) ,No,No,No
Zhao_2019_Radiomics_signature_extracted_from_DW_MRI,No potential biases were discussed prior to AI development,"More than two attributes in the list were collected, OR with other attributes",Biases were neither investigated nor corrected for,The clinical setting was not reported ,No,This study only used single center data --> no external validation;,"local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, however intended use and end-user requirement was described; OR, multiple stakeholders were present for AI development, no intented use or requirement was decribed",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has not been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has not been evaluated against real-world data (test data),Explainibility has not been defined at the design phase,Explainability has not been defined or not evaluated with end-users,Yes,Yes,Evaluation was not conducted using standardized and best practices,No,No,No
Zhang_2023_Clinical-radiomics-based_treatment_decision_support,No potential biases were discussed prior to AI development,"More than two attributes in the list were collected, OR with other attributes",Biases were investigated and reported,The clinical setting was not reported ,Yes,"Evaluation was performed using external dataset from one other site (or same source, eg public available);","local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, however intended use and end-user requirement was described; OR, multiple stakeholders were present for AI development, no intented use or requirement was decribed",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has not been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has been evaluated against real-world data (test data),Explainibility has not been defined at the design phase,Explainability has not been defined or not evaluated with end-users,Yes,Yes,A seperate test set was used to evaluate the AI tool and reported on using appropriate evaluation metrics (eg sensitivity and specificity) ,No,No,No
Zhang_2021_Machine_learning-based_radiomics_nomogram,No potential biases were discussed prior to AI development,"More than two attributes in the list were collected, OR with other attributes",Biases were investigated and reported,The clinical setting was not reported ,Yes,This study only used single center data --> no external validation;,"local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, however intended use and end-user requirement was described; OR, multiple stakeholders were present for AI development, no intented use or requirement was decribed",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has not been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has been evaluated against real-world data (test data),Explainibility has not been defined at the design phase,Explainability has not been defined or not evaluated with end-users,Yes,Yes,A seperate test set was used to evaluate the AI tool and reported on using appropriate evaluation metrics (eg sensitivity and specificity) ,No,No,No
Zhai_2022_Development_and_validation_of_a_preoperative,No potential biases were discussed prior to AI development,"More than two attributes in the list were collected, OR with other attributes","Biases were also corrected for by mitigation measures (In case of no biases found, 3 also applies)",The clinical setting was not reported ,Yes,This study only used single center data --> no external validation;,"local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, however intended use and end-user requirement was described; OR, multiple stakeholders were present for AI development, no intented use or requirement was decribed",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has not been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has been evaluated against real-world data (test data),Explainibility has not been defined at the design phase,Explainability has not been defined or not evaluated with end-users,Yes,No,A seperate test set was used to evaluate the AI tool and reported on using appropriate evaluation metrics (eg sensitivity and specificity) ,No,No,No
Yin_2023_Clinical-radiomics_models_Based_on_plain-X-rays,No potential biases were discussed prior to AI development,"More than two attributes in the list were collected, OR with other attributes",Biases were investigated and reported,The clinical setting was not reported ,Yes,This study only used single center data --> no external validation;,"local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, however intended use and end-user requirement was described; OR, multiple stakeholders were present for AI development, no intented use or requirement was decribed",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has not been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has been evaluated against real-world data (test data) and the AI tool's robustness has been optimized (if applicable) using mitigation methods,Explainibility has not been defined at the design phase,Explainability has not been defined or not evaluated with end-users,Yes,Yes,The AI tool was compared to current standard practice (ie evaluation metrics on test set should be compared to same metrics for current clinical tests - so for example how did it compare to radiologists),No,No,No
Yin_2019_Comparison_of_radiomics_machine_learning_classifiers,No potential biases were discussed prior to AI development,"More than two attributes in the list were collected, OR with other attributes","Biases were also corrected for by mitigation measures (In case of no biases found, 3 also applies)",The clinical setting was not reported ,Yes,This study only used single center data --> no external validation;,"local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, however intended use and end-user requirement was described; OR, multiple stakeholders were present for AI development, no intented use or requirement was decribed",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has not been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has been evaluated against real-world data (test data),Explainibility has not been defined at the design phase,Explainability has not been defined or not evaluated with end-users,Yes,Yes,A seperate test set was used to evaluate the AI tool and reported on using appropriate evaluation metrics (eg sensitivity and specificity) ,No,No,No
Yin_2019_Clinical-radiomics_nomograms_for_pre-operative_differentiation,No potential biases were discussed prior to AI development,"More than two attributes in the list were collected, OR with other attributes",Biases were investigated and reported,The clinical setting was not reported ,Yes,This study only used single center data --> no external validation;,"local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, however intended use and end-user requirement was described; OR, multiple stakeholders were present for AI development, no intented use or requirement was decribed",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has not been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has been evaluated against real-world data (test data),Explainibility has not been defined at the design phase,Explainability has not been defined or not evaluated with end-users,Yes,Yes,A seperate test set was used to evaluate the AI tool and reported on using appropriate evaluation metrics (eg sensitivity and specificity) ,No,No,No
Yang_2022_prognosis_prediction_of_extremity,No potential biases were discussed prior to AI development,"More than two attributes in the list were collected, OR with other attributes",Biases were investigated and reported,The clinical setting was not reported ,No,This study only used single center data --> no external validation;,"local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, however intended use and end-user requirement was described; OR, multiple stakeholders were present for AI development, no intented use or requirement was decribed",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has not been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has been evaluated against real-world data (test data),Explainibility has not been defined at the design phase,Explainability has not been defined or not evaluated with end-users,Yes,Yes,A seperate test set was used to evaluate the AI tool and reported on using appropriate evaluation metrics (eg sensitivity and specificity) ,No,No,No
Yang_2022_Deep_Learning_and_radiomics,No potential biases were discussed prior to AI development,"More than two attributes in the list were collected, OR with other attributes","Biases were also corrected for by mitigation measures (In case of no biases found, 3 also applies)",The clinical setting was not reported ,Yes,This study only used single center data --> no external validation;,"local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, and no intended use and user requirement was described",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has not been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has been evaluated against real-world data (test data),Explainibility has not been defined at the design phase,Explainability has not been defined or not evaluated with end-users,No,Yes,A seperate test set was used to evaluate the AI tool and reported on using appropriate evaluation metrics (eg sensitivity and specificity) ,No,No,No
Yang_2021_Development_of_a_malignancy_potential,No potential biases were discussed prior to AI development,"More than two attributes in the list were collected, OR with other attributes","Biases were also corrected for by mitigation measures (In case of no biases found, 3 also applies)",The clinical setting was not reported ,No,This study only used single center data --> no external validation;,"local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,Monitoring or quality control measures have been implemented for either the inputs or outputs ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, however intended use and end-user requirement was described; OR, multiple stakeholders were present for AI development, no intented use or requirement was decribed",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has not been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has been evaluated against real-world data (test data),Explainibility has not been defined at the design phase,Explainability has been evaluated in silico OR with end users involved in the development ,Yes,Yes,A seperate test set was used to evaluate the AI tool and reported on using appropriate evaluation metrics (eg sensitivity and specificity) ,No,No,No
Yamazawa_2022_MRI_Based_radiomics_differentiates,No potential biases were discussed prior to AI development,"At least the two attributes in the list collected; (list :sex OR gender, age, ethnicity, risk factors(as 1 item), comorbidities or disabilities)",Biases were neither investigated nor corrected for,The clinical setting was not reported ,Yes,This study only used single center data --> no external validation;,"local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, however intended use and end-user requirement was described; OR, multiple stakeholders were present for AI development, no intented use or requirement was decribed",Yes,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has not been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has been evaluated against real-world data (test data),Explainibility has not been defined at the design phase,Explainability has not been defined or not evaluated with end-users,Yes,Yes,The AI tool was compared to current standard practice (ie evaluation metrics on test set should be compared to same metrics for current clinical tests - so for example how did it compare to radiologists),No,No,No
Xu_2020_soft-tissue-sarcoma-preoperative-mri-based-radiomics-and-machine-learning-may-be-accurate-predictors-of,No potential biases were discussed prior to AI development,"At least the two attributes in the list collected; (list :sex OR gender, age, ethnicity, risk factors(as 1 item), comorbidities or disabilities)","Biases were also corrected for by mitigation measures (In case of no biases found, 3 also applies)",The clinical setting was not reported ,Yes,This study only used single center data --> no external validation;,"local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, however intended use and end-user requirement was described; OR, multiple stakeholders were present for AI development, no intented use or requirement was decribed",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has not been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has been evaluated against real-world data (test data),Explainibility has not been defined at the design phase,Explainability has not been defined or not evaluated with end-users,Yes,No,Evaluation was not conducted using standardized and best practices,No,No,No
Xu_2018_CT_texture_analysis_can_be_a_potential_tool,No potential biases were discussed prior to AI development,"More than two attributes in the list were collected, OR with other attributes",Biases were investigated and reported,The clinical setting was not reported ,No,This study only used single center data --> no external validation;,"local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, however intended use and end-user requirement was described; OR, multiple stakeholders were present for AI development, no intented use or requirement was decribed",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has not been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has been evaluated against real-world data (test data),Explainibility has not been defined at the design phase,Explainability has not been defined or not evaluated with end-users,Yes,Yes,A seperate test set was used to evaluate the AI tool and reported on using appropriate evaluation metrics (eg sensitivity and specificity) ,No,No,No
Xu_2014_Texture_analysis_on_F-FDG_PET,No potential biases were discussed prior to AI development,"At least the two attributes in the list collected; (list :sex OR gender, age, ethnicity, risk factors(as 1 item), comorbidities or disabilities)",Biases were neither investigated nor corrected for,The clinical setting was not reported ,No,This study only used single center data --> no external validation;,"local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, however intended use and end-user requirement was described; OR, multiple stakeholders were present for AI development, no intented use or requirement was decribed",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has not been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has not been evaluated against real-world data (test data),Explainibility has not been defined at the design phase,Explainability has not been defined or not evaluated with end-users,Yes,Yes,Evaluation was not conducted using standardized and best practices,No,No,No
Xie_2019_Preliminary_utilization_of_radiomics,No potential biases were discussed prior to AI development,"More than two attributes in the list were collected, OR with other attributes",Biases were neither investigated nor corrected for,The clinical setting was not reported ,No,This study only used single center data --> no external validation;,"local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, and no intended use and user requirement was described",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has not been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has not been evaluated against real-world data (test data),Explainibility has not been defined at the design phase,Explainability has not been defined or not evaluated with end-users,No,Yes,Evaluation was not conducted using standardized and best practices,No,No,No
White_2023_T2-weighted_MRI_radiomics,No potential biases were discussed prior to AI development,"More than two attributes in the list were collected, OR with other attributes",Biases were neither investigated nor corrected for,The clinical setting was not reported ,Yes,This study only used single center data --> no external validation;,"local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, however intended use and end-user requirement was described; OR, multiple stakeholders were present for AI development, no intented use or requirement was decribed",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has not been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has not been evaluated against real-world data (test data),Explainibility has not been defined at the design phase,Explainability has not been defined or not evaluated with end-users,Yes,Yes,Evaluation was not conducted using standardized and best practices,No,No,No
Wei_2023_predictive-value-of-a-radiomics-nomogram-model-based-on-contrast-enhanced-computed-tomography-for-kit,No potential biases were discussed prior to AI development,"More than two attributes in the list were collected, OR with other attributes","Biases were also corrected for by mitigation measures (In case of no biases found, 3 also applies)",The clinical setting was not reported ,Yes,This study only used single center data --> no external validation;,"local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, and no intended use and user requirement was described",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has not been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has been evaluated against real-world data (test data),Explainibility has not been defined at the design phase,Explainability has not been defined or not evaluated with end-users,No,Yes,A seperate test set was used to evaluate the AI tool and reported on using appropriate evaluation metrics (eg sensitivity and specificity) ,No,No,No
Wang_2022_Prediction_of_recurrence-free_survival,No potential biases were discussed prior to AI development,"More than two attributes in the list were collected, OR with other attributes","Biases were also corrected for by mitigation measures (In case of no biases found, 3 also applies)",The clinical setting was not reported ,Yes,This study only used single center data --> no external validation;,"local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, however intended use and end-user requirement was described; OR, multiple stakeholders were present for AI development, no intented use or requirement was decribed",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has not been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has not been evaluated against real-world data (test data),Explainibility has not been defined at the design phase,Explainability has not been defined or not evaluated with end-users,Yes,Yes,A seperate test set was used to evaluate the AI tool and reported on using appropriate evaluation metrics (eg sensitivity and specificity) ,No,No,No
Wang_2021_Prediction_of_the_early_recurrence,No potential biases were discussed prior to AI development,"More than two attributes in the list were collected, OR with other attributes",Biases were investigated and reported,"Clinical setting outlined (eg primary healthcare centres, hospitals, home care, low vs high-resource settings, one or multiple countries)",Yes,This study only used single center data --> no external validation;,"local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, however intended use and end-user requirement was described; OR, multiple stakeholders were present for AI development, no intented use or requirement was decribed",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has not been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has not been evaluated against real-world data (test data),Explainibility has not been defined at the design phase,Explainability has not been defined or not evaluated with end-users,Yes,Yes,Evaluation was not conducted using standardized and best practices,No,No,No
Wang_2021_Differentiation_gastric_schwonnomas_from_GIST,No potential biases were discussed prior to AI development,"At least the two attributes in the list collected; (list :sex OR gender, age, ethnicity, risk factors(as 1 item), comorbidities or disabilities)",Biases were investigated and reported,The clinical setting was not reported ,No,This study only used single center data --> no external validation;,"local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, however intended use and end-user requirement was described; OR, multiple stakeholders were present for AI development, no intented use or requirement was decribed",No,The AI tool was not evaluated for user experience,The AI tool was evaluated for clinical utility and safety,Data acquisiton and possible variation of the data source to the real world has not been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has been evaluated against real-world data (test data),Explainibility has not been defined at the design phase,Explainability has not been defined or not evaluated with end-users,Yes,Yes,The AI tool was compared to current standard practice (ie evaluation metrics on test set should be compared to same metrics for current clinical tests - so for example how did it compare to radiologists),No,No,No
Wang_2017_Predictive_value_and_modeling_analysis,No potential biases were discussed prior to AI development,"More than two attributes in the list were collected, OR with other attributes",Biases were neither investigated nor corrected for,The clinical setting was not reported ,No,This study only used single center data --> no external validation;,"local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, and no intended use and user requirement was described",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has not been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has not been evaluated against real-world data (test data),Explainibility has not been defined at the design phase,Explainability has not been defined or not evaluated with end-users,No,Yes,Evaluation was not conducted using standardized and best practices,No,No,No
VonSchaky_2022_Development_and_Evaluation_of_ML_models,No potential biases were discussed prior to AI development,"More than two attributes in the list were collected, OR with other attributes",Biases were neither investigated nor corrected for,"Clinical setting outlined (eg primary healthcare centres, hospitals, home care, low vs high-resource settings, one or multiple countries)",Yes,"Evaluation was performed using external dataset from one other site (or same source, eg public available);","local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, however intended use and end-user requirement was described; OR, multiple stakeholders were present for AI development, no intented use or requirement was decribed",No,The AI tool was not evaluated for user experience,The AI tool was evaluated for clinical utility and safety,Data acquisiton and possible variation of the data source to the real world has not been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has been evaluated against real-world data (test data),Explainibility has not been defined at the design phase,Explainability has not been defined or not evaluated with end-users,Yes,Yes,The AI tool was compared to current standard practice (ie evaluation metrics on test set should be compared to same metrics for current clinical tests - so for example how did it compare to radiologists),No,No,No
Tian_2022_Fisher_Discriminant_model_based_on_LASSO,No potential biases were discussed prior to AI development,"More than two attributes in the list were collected, OR with other attributes",Biases were neither investigated nor corrected for,The clinical setting was not reported ,Yes,This study only used single center data --> no external validation;,"local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, however intended use and end-user requirement was described; OR, multiple stakeholders were present for AI development, no intented use or requirement was decribed",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has not been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has not been evaluated against real-world data (test data),Explainibility has not been defined at the design phase,Explainability has not been defined or not evaluated with end-users,Yes,Yes,Evaluation was not conducted using standardized and best practices,No,No,No
Sharma_2021_Bone_Cancer_Detection,No potential biases were discussed prior to AI development,No relevant attributes of the patient were collected;,Biases were neither investigated nor corrected for,The clinical setting was not reported ,No,This study only used single center data --> no external validation;,"local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, however intended use and end-user requirement was described; OR, multiple stakeholders were present for AI development, no intented use or requirement was decribed",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has not been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has been evaluated against real-world data (test data),Explainibility has not been defined at the design phase,Explainability has not been defined or not evaluated with end-users,Yes,No,Evaluation was not conducted using standardized and best practices,No,No,No
Shao_2021_A_contrast-enhanced_CT-based_radiomics_nomogram,No potential biases were discussed prior to AI development,"More than two attributes in the list were collected, OR with other attributes",Biases were investigated and reported,The clinical setting was not reported ,Yes,This study only used single center data --> no external validation;,"local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, however intended use and end-user requirement was described; OR, multiple stakeholders were present for AI development, no intented use or requirement was decribed",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has not been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has been evaluated against real-world data (test data),Explainibility has not been defined at the design phase,Explainability has not been defined or not evaluated with end-users,Yes,Yes,A seperate test set was used to evaluate the AI tool and reported on using appropriate evaluation metrics (eg sensitivity and specificity) ,No,No,No
Shang_2021_Multi_Parametric_MRI_based_radiomics,No potential biases were discussed prior to AI development,"More than two attributes in the list were collected, OR with other attributes","Biases were also corrected for by mitigation measures (In case of no biases found, 3 also applies)",The clinical setting was not reported ,Yes,This study only used single center data --> no external validation;,"local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, however intended use and end-user requirement was described; OR, multiple stakeholders were present for AI development, no intented use or requirement was decribed",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has not been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has not been evaluated against real-world data (test data),Explainibility has not been defined at the design phase,Explainability has not been defined or not evaluated with end-users,Yes,No,A seperate test set was used to evaluate the AI tool and reported on using appropriate evaluation metrics (eg sensitivity and specificity) ,No,No,No
Pereira_2021_Machine_Learning-based_CT_Radiomics_features,"Potential biases in at least 1 group (group attributes, medical profile, human biases) were discussed prior to AI development","More than two attributes in the list were collected, OR with other attributes","Biases were also corrected for by mitigation measures (In case of no biases found, 3 also applies)",The clinical setting was not reported ,Yes,This study only used single center data --> no external validation;,"local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, however intended use and end-user requirement was described; OR, multiple stakeholders were present for AI development, no intented use or requirement was decribed",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has been evaluated against real-world data (test data),Explainibility has not been defined at the design phase,Explainability has not been defined or not evaluated with end-users,Yes,Yes,A seperate test set was used to evaluate the AI tool and reported on using appropriate evaluation metrics (eg sensitivity and specificity) ,No,No,No
Peng_2021_Predicting_distant_metastases_in_STS,No potential biases were discussed prior to AI development,No relevant attributes of the patient were collected;,Biases were neither investigated nor corrected for,The clinical setting was not reported ,No,This study only used single center data --> no external validation;,"local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,Monitoring or quality control measures have been implemented for either the inputs or outputs ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, however intended use and end-user requirement was described; OR, multiple stakeholders were present for AI development, no intented use or requirement was decribed",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has not been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has not been evaluated against real-world data (test data),Explainibility has not been defined at the design phase,Explainability has been evaluated in silico OR with end users involved in the development ,Yes,No,Evaluation was not conducted using standardized and best practices,No,No,No
Pan_2021_Using_Machine_Learning_to_unravel,No potential biases were discussed prior to AI development,"More than two attributes in the list were collected, OR with other attributes",Biases were investigated and reported,The clinical setting was not reported ,No,Evaluation was performed using external dataset from multiple sites;,"local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,Monitoring or quality control measures have been implemented for either the inputs or outputs ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, and no intended use and user requirement was described",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has not been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has been evaluated against real-world data (test data),"At least one of the following areas is discussed: (i) the goal of the explanations (eg global description of the model’s behaviour vs local explanation of each AI decision), (ii) the most suitable approach for AI explainability and (iii) the potential limitations to anticipate and monitor (eg over-reliance of the end-users on the AI decision)",Explainability has been evaluated in silico OR with end users involved in the development ,No,Yes,A seperate test set was used to evaluate the AI tool and reported on using appropriate evaluation metrics (eg sensitivity and specificity) ,No,No,No
Mutlu_2021_Machine_Learning-Based_CT_Texture_Analysis,No potential biases were discussed prior to AI development,"More than two attributes in the list were collected, OR with other attributes",Biases were investigated and reported,The clinical setting was not reported ,Yes,This study only used single center data --> no external validation;,"local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, and no intended use and user requirement was described",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has been evaluated against real-world data (test data),Explainibility has not been defined at the design phase,Explainability has not been defined or not evaluated with end-users,No,Yes,A seperate test set was used to evaluate the AI tool and reported on using appropriate evaluation metrics (eg sensitivity and specificity) ,No,No,No
Minoda_2022_Efficacy_of_ultrasound_endoscopy_with_AI,No potential biases were discussed prior to AI development,"At least the two attributes in the list collected; (list :sex OR gender, age, ethnicity, risk factors(as 1 item), comorbidities or disabilities)",Biases were neither investigated nor corrected for,The clinical setting was not reported ,No,This study only used single center data --> no external validation;,"local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, however intended use and end-user requirement was described; OR, multiple stakeholders were present for AI development, no intented use or requirement was decribed",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has not been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has been evaluated against real-world data (test data),Explainibility has not been defined at the design phase,Explainability has not been defined or not evaluated with end-users,Yes,Yes,A seperate test set was used to evaluate the AI tool and reported on using appropriate evaluation metrics (eg sensitivity and specificity) ,No,No,No
Mayerhoefer_2008_Are_Signal_Intensity_and_homogeneity_useful,"Potential biases in at least 1 group (group attributes, medical profile, human biases) were discussed prior to AI development","More than two attributes in the list were collected, OR with other attributes",Biases were neither investigated nor corrected for,The clinical setting was not reported ,No,This study only used single center data --> no external validation;,"local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, however intended use and end-user requirement was described; OR, multiple stakeholders were present for AI development, no intented use or requirement was decribed",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has not been evaluated against real-world data (test data),Explainibility has not been defined at the design phase,Explainability has not been defined or not evaluated with end-users,Yes,No,Evaluation was not conducted using standardized and best practices,No,No,No
Malinauskaite_2020_Radiomics_and_Machine_learning_differentiate,No potential biases were discussed prior to AI development,"More than two attributes in the list were collected, OR with other attributes",Biases were investigated and reported,The clinical setting was not reported ,Yes,This study only used single center data --> no external validation;,"local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, and no intended use and user requirement was described",No,The AI tool was not evaluated for user experience,The AI tool was evaluated for clinical utility and safety,Data acquisiton and possible variation of the data source to the real world has not been discussed,"The representative of the training data to the real-world data was evaluated and enriched accordingly;Note ""real world data"" has to be data taken from a cinical setting",The AI tool has not been evaluated against real-world data (test data),Explainibility has not been defined at the design phase,Explainability has not been defined or not evaluated with end-users,No,Yes,Evaluation was not conducted using standardized and best practices,No,No,No
Liu_2023_Prediction_of_Ki-67_expression,No potential biases were discussed prior to AI development,"More than two attributes in the list were collected, OR with other attributes",Biases were investigated and reported,The clinical setting was not reported ,No,"Evaluation was performed using external dataset from one other site (or same source, eg public available);","local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, however intended use and end-user requirement was described; OR, multiple stakeholders were present for AI development, no intented use or requirement was decribed",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has not been discussed,The representative of the training data to the real-world data was evaluated,The AI tool has been evaluated against real-world data (test data),Explainibility has not been defined at the design phase,Explainability has not been defined or not evaluated with end-users,Yes,Yes,A seperate test set was used to evaluate the AI tool and reported on using appropriate evaluation metrics (eg sensitivity and specificity) ,No,No,No
Liu_2023_postoperative_relapse_prediction_in_patients_with,No potential biases were discussed prior to AI development,"More than two attributes in the list were collected, OR with other attributes","Biases were also corrected for by mitigation measures (In case of no biases found, 3 also applies)",The clinical setting was not reported ,Yes,This study only used single center data --> no external validation;,"local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, however intended use and end-user requirement was described; OR, multiple stakeholders were present for AI development, no intented use or requirement was decribed",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has not been discussed,The representative of the training data to the real-world data was evaluated,The AI tool has not been evaluated against real-world data (test data),Explainibility has not been defined at the design phase,Explainability has not been defined or not evaluated with end-users,Yes,Yes,Evaluation was not conducted using standardized and best practices,No,No,No
Liu_2022_Deep_Learning_radiomic_nomogram,No potential biases were discussed prior to AI development,"More than two attributes in the list were collected, OR with other attributes","Biases were also corrected for by mitigation measures (In case of no biases found, 3 also applies)",The clinical setting was not reported ,No,Evaluation was performed using external dataset from multiple sites;,"local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,Monitoring or quality control measures have been implemented for either the inputs or outputs ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, however intended use and end-user requirement was described; OR, multiple stakeholders were present for AI development, no intented use or requirement was decribed",No,The AI tool was not evaluated for user experience,The AI tool was evaluated for clinical utility and safety,Data acquisiton and possible variation of the data source to the real world has been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has been evaluated against real-world data (test data),Explainibility has not been defined at the design phase,Explainability has been evaluated in silico OR with end users involved in the development ,Yes,Yes,The AI tool was compared to current standard practice (ie evaluation metrics on test set should be compared to same metrics for current clinical tests - so for example how did it compare to radiologists),No,No,No
Liu_2022_A_deep_Learning-machine_Learning_fusion_approach,No potential biases were discussed prior to AI development,"More than two attributes in the list were collected, OR with other attributes",Biases were neither investigated nor corrected for,"Clinical setting outlined (eg primary healthcare centres, hospitals, home care, low vs high-resource settings, one or multiple countries)",Yes,This study only used single center data --> no external validation;,"local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, however intended use and end-user requirement was described; OR, multiple stakeholders were present for AI development, no intented use or requirement was decribed",No,The AI tool was not evaluated for user experience,The AI tool was evaluated for clinical utility and safety,Data acquisiton and possible variation of the data source to the real world has not been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has been evaluated against real-world data (test data),Explainibility has not been defined at the design phase,Explainability has not been defined or not evaluated with end-users,Yes,Yes,The AI tool was compared to current standard practice (ie evaluation metrics on test set should be compared to same metrics for current clinical tests - so for example how did it compare to radiologists),No,No,No
Liu_2021_Pretreatment_Prediction_of_Relapse,No potential biases were discussed prior to AI development,"More than two attributes in the list were collected, OR with other attributes",Biases were neither investigated nor corrected for,The clinical setting was not reported ,Yes,Evaluation was performed using external dataset from multiple sites;,"local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, however intended use and end-user requirement was described; OR, multiple stakeholders were present for AI development, no intented use or requirement was decribed",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has not been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has been evaluated against real-world data (test data),Explainibility has not been defined at the design phase,Explainability has not been defined or not evaluated with end-users,Yes,Yes,A seperate test set was used to evaluate the AI tool and reported on using appropriate evaluation metrics (eg sensitivity and specificity) ,No,No,No
Liang_2022_Deep_Learning_Radiomics_Nomogram,"Potential biases in at least 1 group (group attributes, medical profile, human biases) were discussed prior to AI development","More than two attributes in the list were collected, OR with other attributes","Biases were also corrected for by mitigation measures (In case of no biases found, 3 also applies)",The clinical setting was not reported ,No,Evaluation was performed using external dataset from multiple sites;,"local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,Monitoring or quality control measures have been implemented for either the inputs or outputs ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, however intended use and end-user requirement was described; OR, multiple stakeholders were present for AI development, no intented use or requirement was decribed",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has been discussed,"The representative of the training data to the real-world data was evaluated and enriched accordingly;Note ""real world data"" has to be data taken from a cinical setting",The AI tool has been evaluated against real-world data (test data) and the AI tool's robustness has been optimized (if applicable) using mitigation methods,Explainibility has not been defined at the design phase,Explainability has been evaluated in silico OR with end users involved in the development ,Yes,Yes,A seperate test set was used to evaluate the AI tool and reported on using appropriate evaluation metrics (eg sensitivity and specificity) ,No,No,No
Lin_2023_Prediction_of_the_mitotic_index,No potential biases were discussed prior to AI development,"More than two attributes in the list were collected, OR with other attributes",Biases were investigated and reported,The clinical setting was not reported ,Yes,This study only used single center data --> no external validation;,"local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, however intended use and end-user requirement was described; OR, multiple stakeholders were present for AI development, no intented use or requirement was decribed",No,The AI tool was not evaluated for user experience,The AI tool was evaluated for clinical utility and safety,Data acquisiton and possible variation of the data source to the real world has been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has been evaluated against real-world data (test data),Explainibility has not been defined at the design phase,Explainability has not been defined or not evaluated with end-users,Yes,Yes,The AI tool was compared to current standard practice (ie evaluation metrics on test set should be compared to same metrics for current clinical tests - so for example how did it compare to radiologists),No,No,No
Li_2023_Primary_Bone_Tumor_Detection_and_Classification,No potential biases were discussed prior to AI development,No relevant attributes of the patient were collected;,Biases were neither investigated nor corrected for,The clinical setting was not reported ,Yes,"Evaluation was performed using external dataset from one other site (or same source, eg public available);","local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, however intended use and end-user requirement was described; OR, multiple stakeholders were present for AI development, no intented use or requirement was decribed",No,The AI tool was not evaluated for user experience,The AI tool was evaluated for clinical utility and safety,Data acquisiton and possible variation of the data source to the real world has not been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has been evaluated against real-world data (test data),Explainibility has not been defined at the design phase,Explainability has not been defined or not evaluated with end-users,Yes,Yes,The AI tool was compared to current standard practice (ie evaluation metrics on test set should be compared to same metrics for current clinical tests - so for example how did it compare to radiologists),No,No,No
Li_2023_Development_and_Validation,No potential biases were discussed prior to AI development,"More than two attributes in the list were collected, OR with other attributes",Biases were investigated and reported,The clinical setting was not reported ,Yes,This study only used single center data --> no external validation;,"local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,Multiple stakeholders were present for AI development and compiled information on the AI tool’s intended use and end-user requirements,No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has not been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has been evaluated against real-world data (test data),Explainibility has not been defined at the design phase,Explainability has not been defined or not evaluated with end-users,Yes,Yes,A seperate test set was used to evaluate the AI tool and reported on using appropriate evaluation metrics (eg sensitivity and specificity) ,No,No,No
Leporq_2020_MRI-based_Radiomics_to_predict,"Potential biases in at least 1 group (group attributes, medical profile, human biases) were discussed prior to AI development",No relevant attributes of the patient were collected;,Biases were investigated and reported,"Clinical setting outlined (eg primary healthcare centres, hospitals, home care, low vs high-resource settings, one or multiple countries)",No,Evaluation was performed using external dataset from multiple sites;,local clinical validity has been discussed and evaluated,Risks regarding the AI lifecycle have not been described,No documentation has been provided,No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, however intended use and end-user requirement was described; OR, multiple stakeholders were present for AI development, no intented use or requirement was decribed",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has been evaluated against real-world data (test data),Explainibility has not been defined at the design phase,Explainability has not been defined or not evaluated with end-users,Yes,Yes,A seperate test set was used to evaluate the AI tool and reported on using appropriate evaluation metrics (eg sensitivity and specificity) ,No,No,No
Lee_2021_Radiomics_DW_MRI,No potential biases were discussed prior to AI development,"At least the two attributes in the list collected; (list :sex OR gender, age, ethnicity, risk factors(as 1 item), comorbidities or disabilities)","Biases were also corrected for by mitigation measures (In case of no biases found, 3 also applies)",The clinical setting was not reported ,Yes,This study only used single center data --> no external validation;,"local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, however intended use and end-user requirement was described; OR, multiple stakeholders were present for AI development, no intented use or requirement was decribed",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has been evaluated against real-world data (test data),Explainibility has not been defined at the design phase,Explainability has not been defined or not evaluated with end-users,Yes,Yes,A seperate test set was used to evaluate the AI tool and reported on using appropriate evaluation metrics (eg sensitivity and specificity) ,No,No,No
Lee_2023_Ensemble_learning-based_radiomics_with_multi-sequence_MRI,"Potential biases in at least 1 group (group attributes, medical profile, human biases) were discussed prior to AI development","At least the two attributes in the list collected; (list :sex OR gender, age, ethnicity, risk factors(as 1 item), comorbidities or disabilities)",Biases were neither investigated nor corrected for,The clinical setting was not reported ,Yes,This study only used single center data --> no external validation;,"local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, however intended use and end-user requirement was described; OR, multiple stakeholders were present for AI development, no intented use or requirement was decribed",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has not been evaluated against real-world data (test data),Explainibility has not been defined at the design phase,Explainability has not been defined or not evaluated with end-users,Yes,Yes,Evaluation was not conducted using standardized and best practices,No,No,No
Kim_2021_Preliminary_Radiogenomic_Evidence,No potential biases were discussed prior to AI development,"More than two attributes in the list were collected, OR with other attributes",Biases were neither investigated nor corrected for,The clinical setting was not reported ,No,This study only used single center data --> no external validation;,"local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, however intended use and end-user requirement was described; OR, multiple stakeholders were present for AI development, no intented use or requirement was decribed",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has not been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has not been evaluated against real-world data (test data),Explainibility has not been defined at the design phase,Explainability has not been defined or not evaluated with end-users,Yes,Yes,A seperate test set was used to evaluate the AI tool and reported on using appropriate evaluation metrics (eg sensitivity and specificity) ,No,No,No
Kang_2021_Preoperative_CT-based_Deep_Learning_Model,"Potential biases in at least 1 group (group attributes, medical profile, human biases) were discussed prior to AI development","More than two attributes in the list were collected, OR with other attributes",Biases were neither investigated nor corrected for,The clinical setting was not reported ,Yes,"Evaluation was performed using external dataset from one other site (or same source, eg public available);","local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,Monitoring or quality control measures have been implemented for either the inputs or outputs ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, however intended use and end-user requirement was described; OR, multiple stakeholders were present for AI development, no intented use or requirement was decribed",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has not been evaluated against real-world data (test data),"At least one of the following areas is discussed: (i) the goal of the explanations (eg global description of the model’s behaviour vs local explanation of each AI decision), (ii) the most suitable approach for AI explainability and (iii) the potential limitations to anticipate and monitor (eg over-reliance of the end-users on the AI decision)",Explainability has been evaluated in silico OR with end users involved in the development ,Yes,Yes,A seperate test set was used to evaluate the AI tool and reported on using appropriate evaluation metrics (eg sensitivity and specificity) ,No,No,No
Jia_2023_Risk_Stratificaiton_for_1-to-2-cm_GIST,"Potential biases in at least 1 group (group attributes, medical profile, human biases) were discussed prior to AI development","More than two attributes in the list were collected, OR with other attributes",Biases were investigated and reported,The clinical setting was not reported ,Yes,Evaluation was performed using external dataset from multiple sites;,"local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, however intended use and end-user requirement was described; OR, multiple stakeholders were present for AI development, no intented use or requirement was decribed",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has been evaluated against real-world data (test data),Explainibility has not been defined at the design phase,Explainability has not been defined or not evaluated with end-users,Yes,Yes,A seperate test set was used to evaluate the AI tool and reported on using appropriate evaluation metrics (eg sensitivity and specificity) ,No,No,No
Hu_2021_Diffusion_Weighted_Imaging_MRI_under,"Potential biases in at least 1 group (group attributes, medical profile, human biases) were discussed prior to AI development","At least the two attributes in the list collected; (list :sex OR gender, age, ethnicity, risk factors(as 1 item), comorbidities or disabilities)",Biases were neither investigated nor corrected for,"Clinical setting outlined (eg primary healthcare centres, hospitals, home care, low vs high-resource settings, one or multiple countries)",No,This study only used single center data --> no external validation;,"local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,Monitoring or quality control measures have been implemented for either the inputs or outputs ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, and no intended use and user requirement was described",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has not been evaluated against real-world data (test data),Explainibility has not been defined at the design phase,Explainability has not been defined or not evaluated with end-users,No,Yes,Evaluation was not conducted using standardized and best practices,No,No,No
Hu_2021_Machine_Learning_in_Differentiation_Soft_Tissue_Neoplasms,No potential biases were discussed prior to AI development,"More than two attributes in the list were collected, OR with other attributes",Biases were neither investigated nor corrected for,The clinical setting was not reported ,No,This study only used single center data --> no external validation;,"local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, however intended use and end-user requirement was described; OR, multiple stakeholders were present for AI development, no intented use or requirement was decribed",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has not been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has not been evaluated against real-world data (test data),Explainibility has not been defined at the design phase,Explainability has not been defined or not evaluated with end-users,Yes,Yes,A seperate test set was used to evaluate the AI tool and reported on using appropriate evaluation metrics (eg sensitivity and specificity) ,No,No,No
Hermessi_2019_Deep_Feature_Learning_for_STS,No potential biases were discussed prior to AI development,"At least the two attributes in the list collected; (list :sex OR gender, age, ethnicity, risk factors(as 1 item), comorbidities or disabilities)",Biases were neither investigated nor corrected for,The clinical setting was not reported ,Yes,This study only used single center data --> no external validation;,"local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, and no intended use and user requirement was described",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has not been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has not been evaluated against real-world data (test data),Explainibility has not been defined at the design phase,Explainability has not been defined or not evaluated with end-users,No,No,Evaluation was not conducted using standardized and best practices,No,No,No
He_2022_Scoring_System_for_Predicting_NAC_Response,No potential biases were discussed prior to AI development,"More than two attributes in the list were collected, OR with other attributes","Biases were also corrected for by mitigation measures (In case of no biases found, 3 also applies)",The clinical setting was not reported ,Yes,"Evaluation was performed using external dataset from one other site (or same source, eg public available);","local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, however intended use and end-user requirement was described; OR, multiple stakeholders were present for AI development, no intented use or requirement was decribed",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has not been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has been evaluated against real-world data (test data),Explainibility has not been defined at the design phase,Explainability has not been defined or not evaluated with end-users,Yes,Yes,Evaluation was not conducted using standardized and best practices,No,No,No
He_2019_CNN_to_predict_local_Recurrence,No potential biases were discussed prior to AI development,"More than two attributes in the list were collected, OR with other attributes",Biases were neither investigated nor corrected for,The clinical setting was not reported ,No,This study only used single center data --> no external validation;,"local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, however intended use and end-user requirement was described; OR, multiple stakeholders were present for AI development, no intented use or requirement was decribed",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has not been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has not been evaluated against real-world data (test data),Explainibility has not been defined at the design phase,Explainability has not been defined or not evaluated with end-users,Yes,Yes,Evaluation was not conducted using standardized and best practices,No,No,No
He_2023_Query2,"Potential biases in at least 1 group (group attributes, medical profile, human biases) were discussed prior to AI development","More than two attributes in the list were collected, OR with other attributes",Biases were investigated and reported,The clinical setting was not reported ,Yes,This study only used single center data --> no external validation;,"local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,Documentation about 1-2 points (see decription) have been provided),Monitoring or quality control measures have been implemented for either the inputs or outputs ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, however intended use and end-user requirement was described; OR, multiple stakeholders were present for AI development, no intented use or requirement was decribed",Yes,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has not been evaluated against real-world data (test data),Explainibility has not been defined at the design phase,Explainability has been evaluated in silico OR with end users involved in the development ,Yes,No,Evaluation was not conducted using standardized and best practices,No,No,No
Gruber_2017_Diagnostic_heirarchy_of_radiological_features,No potential biases were discussed prior to AI development,"At least the two attributes in the list collected; (list :sex OR gender, age, ethnicity, risk factors(as 1 item), comorbidities or disabilities)",Biases were neither investigated nor corrected for,The clinical setting was not reported ,No,This study only used single center data --> no external validation;,"local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, and no intended use and user requirement was described",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has not been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has not been evaluated against real-world data (test data),Explainibility has not been defined at the design phase,Explainability has not been defined or not evaluated with end-users,No,Yes,Evaluation was not conducted using standardized and best practices,No,No,No
Gitto_2022_3D_vs_2D_MRI_radiomics_in_skeletal_Ewing_sarcoma,No potential biases were discussed prior to AI development,"More than two attributes in the list were collected, OR with other attributes","Biases were also corrected for by mitigation measures (In case of no biases found, 3 also applies)",The clinical setting was not reported ,Yes,This study only used single center data --> no external validation;,"local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, however intended use and end-user requirement was described; OR, multiple stakeholders were present for AI development, no intented use or requirement was decribed",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has not been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has not been evaluated against real-world data (test data),Explainibility has not been defined at the design phase,Explainability has not been defined or not evaluated with end-users,Yes,Yes,Evaluation was not conducted using standardized and best practices,No,No,No
Fradet_2022_Prediction_of_Lipotamous_soft_tissue_malignancy,No potential biases were discussed prior to AI development,"More than two attributes in the list were collected, OR with other attributes","Biases were also corrected for by mitigation measures (In case of no biases found, 3 also applies)",The clinical setting was not reported ,Yes,Evaluation was performed using external dataset from multiple sites;,"local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, however intended use and end-user requirement was described; OR, multiple stakeholders were present for AI development, no intented use or requirement was decribed",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has been evaluated against real-world data (test data) and the AI tool's robustness has been optimized (if applicable) using mitigation methods,Explainibility has not been defined at the design phase,Explainability has not been defined or not evaluated with end-users,Yes,Yes,A seperate test set was used to evaluate the AI tool and reported on using appropriate evaluation metrics (eg sensitivity and specificity) ,No,No,No
Fields_2023_Predicting_STS_Response_to_NAC,No potential biases were discussed prior to AI development,"More than two attributes in the list were collected, OR with other attributes",Biases were neither investigated nor corrected for,The clinical setting was not reported ,Yes,This study only used single center data --> no external validation;,"local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, however intended use and end-user requirement was described; OR, multiple stakeholders were present for AI development, no intented use or requirement was decribed",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has not been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has not been evaluated against real-world data (test data),Explainibility has not been defined at the design phase,Explainability has not been defined or not evaluated with end-users,Yes,Yes,Evaluation was not conducted using standardized and best practices,No,No,No
Fields_2021_Whole_Tumour_3D_volumetric_MRI,No potential biases were discussed prior to AI development,"More than two attributes in the list were collected, OR with other attributes",Biases were neither investigated nor corrected for,The clinical setting was not reported ,No,This study only used single center data --> no external validation;,"local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, however intended use and end-user requirement was described; OR, multiple stakeholders were present for AI development, no intented use or requirement was decribed",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has been discussed,The representative of the training data to the real-world data was evaluated,The AI tool has not been evaluated against real-world data (test data),Explainibility has not been defined at the design phase,Explainability has not been defined or not evaluated with end-users,Yes,Yes,Evaluation was not conducted using standardized and best practices,No,No,No
Feng_2023_CT-based_nomogram_established,"Potential biases in at least 1 group (group attributes, medical profile, human biases) were discussed prior to AI development","More than two attributes in the list were collected, OR with other attributes","Biases were also corrected for by mitigation measures (In case of no biases found, 3 also applies)",The clinical setting was not reported ,No,This study only used single center data --> no external validation;,"local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, and no intended use and user requirement was described",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has not been evaluated against real-world data (test data),Explainibility has not been defined at the design phase,Explainability has not been defined or not evaluated with end-users,No,Yes,Evaluation was not conducted using standardized and best practices,No,No,No
Do_2017_Bone_Tumor_Diagnosis,No potential biases were discussed prior to AI development,No relevant attributes of the patient were collected;,Biases were neither investigated nor corrected for,The clinical setting was not reported ,Yes,This study only used single center data --> no external validation;,"local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,No monitoring or quality control measures of either inputs or outputs have beenimplemented ,Methods for auditing or updating are discussed,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, however intended use and end-user requirement was described; OR, multiple stakeholders were present for AI development, no intented use or requirement was decribed",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has not been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has not been evaluated against real-world data (test data),more than one of the areas has been identified and discussed ,Explainability has been evaluated in silico OR with end users involved in the development ,Yes,Yes,Evaluation was not conducted using standardized and best practices,No,No,No
Ding_2022_MRI-based_Radiomics_in_Distiguishing_Kaposiform,No potential biases were discussed prior to AI development,"More than two attributes in the list were collected, OR with other attributes",Biases were investigated and reported,The clinical setting was not reported ,No,"Evaluation was performed using external dataset from one other site (or same source, eg public available);","local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, however intended use and end-user requirement was described; OR, multiple stakeholders were present for AI development, no intented use or requirement was decribed",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has not been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has been evaluated against real-world data (test data),Explainibility has not been defined at the design phase,Explainability has not been defined or not evaluated with end-users,Yes,Yes,A seperate test set was used to evaluate the AI tool and reported on using appropriate evaluation metrics (eg sensitivity and specificity) ,No,No,No
Deng_2020_Fusion_Of_FDG-PET_Image,No potential biases were discussed prior to AI development,"More than two attributes in the list were collected, OR with other attributes",Biases were neither investigated nor corrected for,The clinical setting was not reported ,No,This study only used single center data --> no external validation;,"local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, and no intended use and user requirement was described",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has not been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has been evaluated against real-world data (test data),Explainibility has not been defined at the design phase,Explainability has not been defined or not evaluated with end-users,No,No,Evaluation was not conducted using standardized and best practices,No,No,No
Dai_2022_Combining_Multiparametric_MRI_features,"Potential biases in at least 1 group (group attributes, medical profile, human biases) were discussed prior to AI development","More than two attributes in the list were collected, OR with other attributes",Biases were investigated and reported,The clinical setting was not reported ,Yes,This study only used single center data --> no external validation;,"local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,Monitoring or quality control measures have been implemented for either the inputs or outputs ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, however intended use and end-user requirement was described; OR, multiple stakeholders were present for AI development, no intented use or requirement was decribed",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has not been evaluated against real-world data (test data),"At least one of the following areas is discussed: (i) the goal of the explanations (eg global description of the model’s behaviour vs local explanation of each AI decision), (ii) the most suitable approach for AI explainability and (iii) the potential limitations to anticipate and monitor (eg over-reliance of the end-users on the AI decision)",Explainability has been evaluated in silico OR with end users involved in the development ,Yes,Yes,Evaluation was not conducted using standardized and best practices,No,No,No
Dai_2020_Differentiation_Of_Pelvic_Osteosarcoma,"Potential biases in at least 1 group (group attributes, medical profile, human biases) were discussed prior to AI development","More than two attributes in the list were collected, OR with other attributes","Biases were also corrected for by mitigation measures (In case of no biases found, 3 also applies)",The clinical setting was not reported ,Yes,This study only used single center data --> no external validation;,"local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, and no intended use and user requirement was described",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has not been evaluated against real-world data (test data),Explainibility has not been defined at the design phase,Explainability has not been defined or not evaluated with end-users,No,Yes,Evaluation was not conducted using standardized and best practices,No,No,No
2023_Djuričić_Directionally Sensitive Fractal Radiomics Compatible With Irregularly Shaped Magnetic Resonance Tumor Regions of Interest: Association With Osteosarcoma Chemoresistance,No potential biases were discussed prior to AI development,"At least the two attributes in the list collected; (list :sex OR gender, age, ethnicity, risk factors(as 1 item), comorbidities or disabilities)",Biases were neither investigated nor corrected for,The clinical setting was not reported ,No,This study only used single center data --> no external validation;,"local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, however intended use and end-user requirement was described; OR, multiple stakeholders were present for AI development, no intented use or requirement was decribed",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has not been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has not been evaluated against real-world data (test data),Explainibility has not been defined at the design phase,Explainability has not been defined or not evaluated with end-users,Yes,Yes,Evaluation was not conducted using standardized and best practices,No,No,No
2020_Dong_Differential Diagnosis of Solitary Fibrous Tumor/Hemangiopericytoma and Angiomatous Meningioma Using Three-Dimensional Magnetic Resonance Imaging Texture Feature Model,No potential biases were discussed prior to AI development,No relevant attributes of the patient were collected;,Biases were neither investigated nor corrected for,The clinical setting was not reported ,No,This study only used single center data --> no external validation;,"local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, however intended use and end-user requirement was described; OR, multiple stakeholders were present for AI development, no intented use or requirement was decribed",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has not been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has been evaluated against real-world data (test data),Explainibility has not been defined at the design phase,Explainability has not been defined or not evaluated with end-users,Yes,No,A seperate test set was used to evaluate the AI tool and reported on using appropriate evaluation metrics (eg sensitivity and specificity) ,No,No,No
2023_Dou_Prediction of high-grade soft-tissue sarcoma using a combined intratumoural and peritumoural MRI-based radiomics nomogram,No potential biases were discussed prior to AI development,"At least the two attributes in the list collected; (list :sex OR gender, age, ethnicity, risk factors(as 1 item), comorbidities or disabilities)",Biases were neither investigated nor corrected for,The clinical setting was not reported ,No,This study only used single center data --> no external validation;,"local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, however intended use and end-user requirement was described; OR, multiple stakeholders were present for AI development, no intented use or requirement was decribed",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has not been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has been evaluated against real-world data (test data),Explainibility has not been defined at the design phase,Explainability has not been defined or not evaluated with end-users,Yes,Yes,A seperate test set was used to evaluate the AI tool and reported on using appropriate evaluation metrics (eg sensitivity and specificity) ,No,No,No
2021_Eweje_Deep Learning for Classification of Bone Lesions on Routine MRI,No potential biases were discussed prior to AI development,"More than two attributes in the list were collected, OR with other attributes",Biases were investigated and reported,The clinical setting was not reported ,No,Evaluation was performed using external dataset from multiple sites;,"local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, however intended use and end-user requirement was described; OR, multiple stakeholders were present for AI development, no intented use or requirement was decribed",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has not been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has been evaluated against real-world data (test data),Explainibility has not been defined at the design phase,Explainability has not been defined or not evaluated with end-users,No,Yes,A seperate test set was used to evaluate the AI tool and reported on using appropriate evaluation metrics (eg sensitivity and specificity) ,No,No,No
2022_Fadli_Natural Changes in Radiological and Radiomics Features on MRIs of Soft-Tissue Sarcomas Naive of Treatment: Correlations With Histology and Patients' Outcomes,No potential biases were discussed prior to AI development,"More than two attributes in the list were collected, OR with other attributes",Biases were investigated and reported,The clinical setting was not reported ,No,This study only used single center data --> no external validation;,"local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, however intended use and end-user requirement was described; OR, multiple stakeholders were present for AI development, no intented use or requirement was decribed",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has not been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has not been evaluated against real-world data (test data),Explainibility has not been defined at the design phase,Explainability has not been defined or not evaluated with end-users,Yes,No,Evaluation was not conducted using standardized and best practices,No,No,No
2023_Findlay_Application of Radiomics to the Differential Diagnosis of Temporal Bone Skull Base Lesions: A Pilot Study,No potential biases were discussed prior to AI development,No relevant attributes of the patient were collected;,Biases were neither investigated nor corrected for,The clinical setting was not reported ,Yes,This study only used single center data --> no external validation;,"local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, however intended use and end-user requirement was described; OR, multiple stakeholders were present for AI development, no intented use or requirement was decribed",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has not been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has not been evaluated against real-world data (test data),Explainibility has not been defined at the design phase,Explainability has not been defined or not evaluated with end-users,Yes,Yes,Evaluation was not conducted using standardized and best practices,No,No,No
2023_Foreman_Development and Evaluation of MR-Based Radiogenomic Models to Differentiate Atypical Lipomatous Tumors from Lipomas,No potential biases were discussed prior to AI development,"More than two attributes in the list were collected, OR with other attributes",Biases were investigated and reported,The clinical setting was not reported ,Yes,"Evaluation was performed using external dataset from one other site (or same source, eg public available);","local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, however intended use and end-user requirement was described; OR, multiple stakeholders were present for AI development, no intented use or requirement was decribed",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has not been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has been evaluated against real-world data (test data),Explainibility has not been defined at the design phase,Explainability has not been defined or not evaluated with end-users,Yes,Yes,The AI tool was compared to current standard practice (ie evaluation metrics on test set should be compared to same metrics for current clinical tests - so for example how did it compare to radiologists),No,No,No
2022_Georgeanu_Malignant Bone Tumors Diagnosis Using Magnetic Resonance Imaging Based on Deep Learning Algorithms,No potential biases were discussed prior to AI development,"More than two attributes in the list were collected, OR with other attributes",Biases were neither investigated nor corrected for,The clinical setting was not reported ,No,This study only used single center data --> no external validation;,"local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,Multiple stakeholders were present for AI development and compiled information on the AI tool’s intended use and end-user requirements,No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has not been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has not been evaluated against real-world data (test data),Explainibility has not been defined at the design phase,Explainability has been evaluated in silico OR with end users involved in the development ,Yes,Yes,Evaluation was not conducted using standardized and best practices,No,No,No
2021_Gitto_CT radiomics-based machine learning classification of atypical cartilaginous tumours and appendicular chondrosarcomas,No potential biases were discussed prior to AI development,"More than two attributes in the list were collected, OR with other attributes","Biases were also corrected for by mitigation measures (In case of no biases found, 3 also applies)",The clinical setting was not reported ,Yes,"Evaluation was performed using external dataset from one other site (or same source, eg public available);","local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,Monitoring or quality control measures have been implemented for either the inputs or outputs ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, however intended use and end-user requirement was described; OR, multiple stakeholders were present for AI development, no intented use or requirement was decribed",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has not been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has been evaluated against real-world data (test data),Explainibility has not been defined at the design phase,Explainability has not been defined or not evaluated with end-users,Yes,Yes,A seperate test set was used to evaluate the AI tool and reported on using appropriate evaluation metrics (eg sensitivity and specificity) ,No,No,No
2022_Gitto_MRI radiomics-based machine learning classification of atypical cartilaginous tumour and grade II chondrosarcoma of long bones,No potential biases were discussed prior to AI development,"More than two attributes in the list were collected, OR with other attributes","Biases were also corrected for by mitigation measures (In case of no biases found, 3 also applies)",The clinical setting was not reported ,Yes,"Evaluation was performed using external dataset from one other site (or same source, eg public available);","local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, however intended use and end-user requirement was described; OR, multiple stakeholders were present for AI development, no intented use or requirement was decribed",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has not been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has been evaluated against real-world data (test data),"At least one of the following areas is discussed: (i) the goal of the explanations (eg global description of the model’s behaviour vs local explanation of each AI decision), (ii) the most suitable approach for AI explainability and (iii) the potential limitations to anticipate and monitor (eg over-reliance of the end-users on the AI decision)",Explainability has been evaluated in silico OR with end users involved in the development ,Yes,Yes,A seperate test set was used to evaluate the AI tool and reported on using appropriate evaluation metrics (eg sensitivity and specificity) ,No,No,No
2020_Hu_A contrast-enhanced MRI-based nomogram to identify lung metastasis in soft-tissue sarcoma: A multi-centre study,No potential biases were discussed prior to AI development,"At least the two attributes in the list collected; (list :sex OR gender, age, ethnicity, risk factors(as 1 item), comorbidities or disabilities)",Biases were investigated and reported,The clinical setting was not reported ,Yes,"Evaluation was performed using external dataset from one other site (or same source, eg public available);","local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, however intended use and end-user requirement was described; OR, multiple stakeholders were present for AI development, no intented use or requirement was decribed",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has not been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has been evaluated against real-world data (test data),Explainibility has not been defined at the design phase,Explainability has not been defined or not evaluated with end-users,Yes,Yes,The AI tool was compared to current standard practice (ie evaluation metrics on test set should be compared to same metrics for current clinical tests - so for example how did it compare to radiologists),No,No,No
2023_Hu_Preoperative contrast-enhanced CT-based radiomics signature for predicting hypoxia-inducible factor 1alpha expression in retroperitoneal sarcoma,No potential biases were discussed prior to AI development,"At least the two attributes in the list collected; (list :sex OR gender, age, ethnicity, risk factors(as 1 item), comorbidities or disabilities)",Biases were investigated and reported,The clinical setting was not reported ,No,This study only used single center data --> no external validation;,"local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, however intended use and end-user requirement was described; OR, multiple stakeholders were present for AI development, no intented use or requirement was decribed",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has not been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has been evaluated against real-world data (test data),Explainibility has not been defined at the design phase,Explainability has not been defined or not evaluated with end-users,Yes,Yes,A seperate test set was used to evaluate the AI tool and reported on using appropriate evaluation metrics (eg sensitivity and specificity) ,No,No,No
2020_Huang_Feasibility of multi-parametric magnetic resonance imaging combined with machine learning in the assessment of necrosis of osteosarcoma after neoadjuvant chemotherapy: a preliminary study,No potential biases were discussed prior to AI development,"At least the two attributes in the list collected; (list :sex OR gender, age, ethnicity, risk factors(as 1 item), comorbidities or disabilities)",Biases were investigated and reported,The clinical setting was not reported ,No,This study only used single center data --> no external validation;,"local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, however intended use and end-user requirement was described; OR, multiple stakeholders were present for AI development, no intented use or requirement was decribed",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has not been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has not been evaluated against real-world data (test data),Explainibility has not been defined at the design phase,Explainability has not been defined or not evaluated with end-users,Yes,Yes,Evaluation was not conducted using standardized and best practices,No,No,No
2010_Juntu_Machine Learning Study of Several Classifiers Trained With Texture Analysis Features to Differentiate Benign from Malignant Soft-Tissue Tumors in T1-MRI Images,No potential biases were discussed prior to AI development,No relevant attributes of the patient were collected;,Biases were neither investigated nor corrected for,The clinical setting was not reported ,No,This study only used single center data --> no external validation;,"local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, and no intended use and user requirement was described",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has not been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has not been evaluated against real-world data (test data),Explainibility has not been defined at the design phase,Explainability has not been defined or not evaluated with end-users,No,No,A seperate test set was used to evaluate the AI tool and reported on using appropriate evaluation metrics (eg sensitivity and specificity) ,No,No,No
2020_Kim_Application of a Convolutional Neural Network in the Diagnosis of Gastric Mesenchymal Tumors on Endoscopic Ultrasonography Images,No potential biases were discussed prior to AI development,"More than two attributes in the list were collected, OR with other attributes",Biases were neither investigated nor corrected for,The clinical setting was not reported ,No,Evaluation was performed using external dataset from multiple sites;,"local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, however intended use and end-user requirement was described; OR, multiple stakeholders were present for AI development, no intented use or requirement was decribed",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has not been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has been evaluated against real-world data (test data),Explainibility has not been defined at the design phase,Explainability has not been defined or not evaluated with end-users,Yes,Yes,The AI tool was compared to current standard practice (ie evaluation metrics on test set should be compared to same metrics for current clinical tests - so for example how did it compare to radiologists),No,No,No
2021_Ambeth Kumar_Bone Cancer Detection Using Feature Extraction with Classification Using K-Nearest Neighbor and Decision Tree Algorithm,No potential biases were discussed prior to AI development,No relevant attributes of the patient were collected;,Biases were neither investigated nor corrected for,The clinical setting was not reported ,No,This study only used single center data --> no external validation;,"local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, and no intended use and user requirement was described",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has not been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has not been evaluated against real-world data (test data),Explainibility has not been defined at the design phase,Explainability has not been defined or not evaluated with end-users,No,No,Evaluation was not conducted using standardized and best practices,No,No,No
2023_Lee_Diagnosis of Marginal Infiltration in Soft Tissue Sarcoma by Radiomics Approach Using T2-Weighted Dixon Sequence,No potential biases were discussed prior to AI development,"More than two attributes in the list were collected, OR with other attributes",Biases were investigated and reported,The clinical setting was not reported ,No,This study only used single center data --> no external validation;,"local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, however intended use and end-user requirement was described; OR, multiple stakeholders were present for AI development, no intented use or requirement was decribed",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has not been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has not been evaluated against real-world data (test data),Explainibility has not been defined at the design phase,Explainability has not been defined or not evaluated with end-users,No,Yes,Evaluation was not conducted using standardized and best practices,No,No,No
2020_Lin_A Delta-radiomics model for preoperative evaluation of Neoadjuvant chemotherapy response in high-grade osteosarcoma,No potential biases were discussed prior to AI development,"More than two attributes in the list were collected, OR with other attributes",Biases were investigated and reported,The clinical setting was not reported ,Yes,This study only used single center data --> no external validation;,"local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, however intended use and end-user requirement was described; OR, multiple stakeholders were present for AI development, no intented use or requirement was decribed",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has not been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has been evaluated against real-world data (test data),Explainibility has not been defined at the design phase,Explainability has not been defined or not evaluated with end-users,Yes,Yes,A seperate test set was used to evaluate the AI tool and reported on using appropriate evaluation metrics (eg sensitivity and specificity) ,No,No,No
2022_Liu_Gastrointestinal stromal tumors diagnosis on multi-center endoscopic ultrasound images using multi-scale image normalization and transfer learning,No potential biases were discussed prior to AI development,"At least the two attributes in the list collected; (list :sex OR gender, age, ethnicity, risk factors(as 1 item), comorbidities or disabilities)",Biases were investigated and reported,The clinical setting was not reported ,No,This study only used single center data --> no external validation;,"local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, however intended use and end-user requirement was described; OR, multiple stakeholders were present for AI development, no intented use or requirement was decribed",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has not been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has been evaluated against real-world data (test data),Explainibility has not been defined at the design phase,Explainability has not been defined or not evaluated with end-users,Yes,Yes,A seperate test set was used to evaluate the AI tool and reported on using appropriate evaluation metrics (eg sensitivity and specificity) ,No,No,No
2022_Liu_Benign and malignant diagnosis of spinal tumors based on deep learning and weighted fusion framework on MRI,No potential biases were discussed prior to AI development,"At least the two attributes in the list collected; (list :sex OR gender, age, ethnicity, risk factors(as 1 item), comorbidities or disabilities)",Biases were neither investigated nor corrected for,The clinical setting was not reported ,Yes,This study only used single center data --> no external validation;,"local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, however intended use and end-user requirement was described; OR, multiple stakeholders were present for AI development, no intented use or requirement was decribed",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has not been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has been evaluated against real-world data (test data),Explainibility has not been defined at the design phase,Explainability has not been defined or not evaluated with end-users,Yes,Yes,The AI tool was compared to current standard practice (ie evaluation metrics on test set should be compared to same metrics for current clinical tests - so for example how did it compare to radiologists),No,No,No
2023_Liu_Differentiating Gastrointestinal Stromal Tumors From Leiomyomas of Upper Digestive Tract Using Convolutional Neural Network Model by Endoscopic Ultrasonography,No potential biases were discussed prior to AI development,"More than two attributes in the list were collected, OR with other attributes",Biases were investigated and reported,The clinical setting was not reported ,No,This study only used single center data --> no external validation;,"local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, however intended use and end-user requirement was described; OR, multiple stakeholders were present for AI development, no intented use or requirement was decribed",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has not been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has been evaluated against real-world data (test data),Explainibility has not been defined at the design phase,Explainability has not been defined or not evaluated with end-users,Yes,No,The AI tool was compared to current standard practice (ie evaluation metrics on test set should be compared to same metrics for current clinical tests - so for example how did it compare to radiologists),No,No,No
2023_Liu_Development and validation of an EUS-based nomogram for prediction of the malignant potential in gastrointestinal stromal tumors,No potential biases were discussed prior to AI development,"More than two attributes in the list were collected, OR with other attributes",Biases were investigated and reported,The clinical setting was not reported ,No,This study only used single center data --> no external validation;,"local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, however intended use and end-user requirement was described; OR, multiple stakeholders were present for AI development, no intented use or requirement was decribed",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has not been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has been evaluated against real-world data (test data),Explainibility has not been defined at the design phase,Explainability has not been defined or not evaluated with end-users,Yes,No,A seperate test set was used to evaluate the AI tool and reported on using appropriate evaluation metrics (eg sensitivity and specificity) ,No,No,No
2022_Liu_Research on imbalance machine learning methods for MRT1WI soft tissue sarcoma data,No potential biases were discussed prior to AI development,No relevant attributes of the patient were collected;,Biases were neither investigated nor corrected for,The clinical setting was not reported ,No,"Evaluation was performed using external dataset from one other site (or same source, eg public available);","local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, however intended use and end-user requirement was described; OR, multiple stakeholders were present for AI development, no intented use or requirement was decribed",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has not been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has been evaluated against real-world data (test data),Explainibility has not been defined at the design phase,Explainability has not been defined or not evaluated with end-users,Yes,No,Evaluation was not conducted using standardized and best practices,No,No,No
2021_Liu_Gastrointestinal stromal tumors: associations between contrastenhanced CT images and KIT exon 11 gene mutation,No potential biases were discussed prior to AI development,"More than two attributes in the list were collected, OR with other attributes",Biases were investigated and reported,The clinical setting was not reported ,Yes,This study only used single center data --> no external validation;,"local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, however intended use and end-user requirement was described; OR, multiple stakeholders were present for AI development, no intented use or requirement was decribed",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has not been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has been evaluated against real-world data (test data),Explainibility has not been defined at the design phase,Explainability has not been defined or not evaluated with end-users,Yes,Yes,A seperate test set was used to evaluate the AI tool and reported on using appropriate evaluation metrics (eg sensitivity and specificity) ,No,No,No
2023_Lu_Artificial intelligence in endoscopic ultrasonography: risk stratification of gastric gastrointestinal stromal tumors,No potential biases were discussed prior to AI development,"More than two attributes in the list were collected, OR with other attributes",Biases were investigated and reported,The clinical setting was not reported ,Yes,Evaluation was performed using external dataset from multiple sites;,"local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, however intended use and end-user requirement was described; OR, multiple stakeholders were present for AI development, no intented use or requirement was decribed",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has not been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has been evaluated against real-world data (test data),Explainibility has not been defined at the design phase,Explainability has not been defined or not evaluated with end-users,Yes,Yes,A seperate test set was used to evaluate the AI tool and reported on using appropriate evaluation metrics (eg sensitivity and specificity) ,No,No,No
"2023_Lu_Artificial Intelligence in the Prediction of Gastrointestinal Stromal Tumors on Endoscopic Ultrasonography Images: Development, Validation and Comparison with Endosonographers",No potential biases were discussed prior to AI development,"More than two attributes in the list were collected, OR with other attributes",Biases were neither investigated nor corrected for,The clinical setting was not reported ,No,Evaluation was performed using external dataset from multiple sites;,"local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, however intended use and end-user requirement was described; OR, multiple stakeholders were present for AI development, no intented use or requirement was decribed",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has not been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has been evaluated against real-world data (test data),Explainibility has not been defined at the design phase,Explainability has not been defined or not evaluated with end-users,Yes,Yes,The AI tool was compared to current standard practice (ie evaluation metrics on test set should be compared to same metrics for current clinical tests - so for example how did it compare to radiologists),No,No,No
2021_Mao_MRI-Based Radiomics Models for Predicting Risk Classification of Gastrointestinal Stromal Tumors,No potential biases were discussed prior to AI development,"More than two attributes in the list were collected, OR with other attributes",Biases were investigated and reported,The clinical setting was not reported ,No,This study only used single center data --> no external validation;,"local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, however intended use and end-user requirement was described; OR, multiple stakeholders were present for AI development, no intented use or requirement was decribed",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has not been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has not been evaluated against real-world data (test data),Explainibility has not been defined at the design phase,Explainability has not been defined or not evaluated with end-users,Yes,Yes,Evaluation was not conducted using standardized and best practices,No,No,No
2019_Martin-Carreras_Radiomic features from MRI distinguish myxomas from myxofibrosarcomas,No potential biases were discussed prior to AI development,"More than two attributes in the list were collected, OR with other attributes",Biases were investigated and reported,The clinical setting was not reported ,Yes,This study only used single center data --> no external validation;,"local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, however intended use and end-user requirement was described; OR, multiple stakeholders were present for AI development, no intented use or requirement was decribed",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has not been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has not been evaluated against real-world data (test data),Explainibility has not been defined at the design phase,Explainability has not been defined or not evaluated with end-users,Yes,Yes,Evaluation was not conducted using standardized and best practices,No,No,No
2023_Mazumder_Bone Cancer Detection Using Deep Learning,No potential biases were discussed prior to AI development,No relevant attributes of the patient were collected;,Biases were neither investigated nor corrected for,The clinical setting was not reported ,No,This study only used single center data --> no external validation;,"local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, and no intended use and user requirement was described",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has not been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has been evaluated against real-world data (test data),Explainibility has not been defined at the design phase,Explainability has not been defined or not evaluated with end-users,No,No,Evaluation was not conducted using standardized and best practices,No,No,No
2023_Megala_Detecting Bone Tumor on Applying Edge Computational Deep Learning Approach,No potential biases were discussed prior to AI development,No relevant attributes of the patient were collected;,Biases were neither investigated nor corrected for,The clinical setting was not reported ,No,This study only used single center data --> no external validation;,"local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, however intended use and end-user requirement was described; OR, multiple stakeholders were present for AI development, no intented use or requirement was decribed",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has not been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has not been evaluated against real-world data (test data),Explainibility has not been defined at the design phase,Explainability has not been defined or not evaluated with end-users,Yes,No,Evaluation was not conducted using standardized and best practices,No,No,No
2020_Minoda_Efficacy of endoscopic ultrasound with artificial intelligence for the diagnosis of gastrointestinal stromal tumors,No potential biases were discussed prior to AI development,"More than two attributes in the list were collected, OR with other attributes",Biases were neither investigated nor corrected for,The clinical setting was not reported ,No,This study only used single center data --> no external validation;,"local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, however intended use and end-user requirement was described; OR, multiple stakeholders were present for AI development, no intented use or requirement was decribed",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has not been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has been evaluated against real-world data (test data),Explainibility has not been defined at the design phase,Explainability has not been defined or not evaluated with end-users,Yes,Yes,A seperate test set was used to evaluate the AI tool and reported on using appropriate evaluation metrics (eg sensitivity and specificity) ,No,No,No
2019_Nakagawa_A multiparametric MRI-based machine learning to distinguish between uterine sarcoma and benign leiomyoma: comparison with 18F-FDG PET/CT,No potential biases were discussed prior to AI development,"At least the two attributes in the list collected; (list :sex OR gender, age, ethnicity, risk factors(as 1 item), comorbidities or disabilities)",Biases were investigated and reported,The clinical setting was not reported ,No,This study only used single center data --> no external validation;,"local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, and no intended use and user requirement was described",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has not been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has not been evaluated against real-world data (test data),Explainibility has not been defined at the design phase,Explainability has not been defined or not evaluated with end-users,No,Yes,Evaluation was not conducted using standardized and best practices,No,No,No
2021_Navarro_Development and External Validation of Deep-Learning-Based Tumor Grading Models in Soft-Tissue Sarcoma Patients Using MR Imaging,No potential biases were discussed prior to AI development,"More than two attributes in the list were collected, OR with other attributes",Biases were investigated and reported,The clinical setting was not reported ,Yes,"Evaluation was performed using external dataset from one other site (or same source, eg public available);","local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, however intended use and end-user requirement was described; OR, multiple stakeholders were present for AI development, no intented use or requirement was decribed",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has not been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has been evaluated against real-world data (test data) and the AI tool's robustness has been optimized (if applicable) using mitigation methods,"At least one of the following areas is discussed: (i) the goal of the explanations (eg global description of the model’s behaviour vs local explanation of each AI decision), (ii) the most suitable approach for AI explainability and (iii) the potential limitations to anticipate and monitor (eg over-reliance of the end-users on the AI decision)",Explainability has not been defined or not evaluated with end-users,Yes,Yes,The AI tool was compared to current standard practice (ie evaluation metrics on test set should be compared to same metrics for current clinical tests - so for example how did it compare to radiologists),No,No,No
2021_Oh_Convolutional neural network-based object detection model to identify gastrointestinal stromal tumors in endoscopic ultrasound images,No potential biases were discussed prior to AI development,No relevant attributes of the patient were collected;,Biases were neither investigated nor corrected for,The clinical setting was not reported ,No,This study only used single center data --> no external validation;,"local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, however intended use and end-user requirement was described; OR, multiple stakeholders were present for AI development, no intented use or requirement was decribed",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has not been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has been evaluated against real-world data (test data),Explainibility has not been defined at the design phase,Explainability has not been defined or not evaluated with end-users,Yes,Yes,A seperate test set was used to evaluate the AI tool and reported on using appropriate evaluation metrics (eg sensitivity and specificity) ,No,No,No
2022_Ouyang_Evaluation of Deep Learning-Based Automated Detection of Primary Spine Tumors on MRI Using the Turing Test,No potential biases were discussed prior to AI development,"More than two attributes in the list were collected, OR with other attributes",Biases were neither investigated nor corrected for,The clinical setting was not reported ,No,This study only used single center data --> no external validation;,"local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, however intended use and end-user requirement was described; OR, multiple stakeholders were present for AI development, no intented use or requirement was decribed",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has not been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has been evaluated against real-world data (test data),Explainibility has not been defined at the design phase,Explainability has not been defined or not evaluated with end-users,Yes,Yes,The AI tool was compared to current standard practice (ie evaluation metrics on test set should be compared to same metrics for current clinical tests - so for example how did it compare to radiologists),No,No,No
2021_Pan_Radiomics Nomograms Based on Non-enhanced MRI and Clinical Risk Factors for the Differentiation of Chondrosarcoma from Enchondroma,No potential biases were discussed prior to AI development,"More than two attributes in the list were collected, OR with other attributes",Biases were investigated and reported,The clinical setting was not reported ,No,This study only used single center data --> no external validation;,"local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, however intended use and end-user requirement was described; OR, multiple stakeholders were present for AI development, no intented use or requirement was decribed",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has not been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has been evaluated against real-world data (test data),Explainibility has not been defined at the design phase,Explainability has not been defined or not evaluated with end-users,Yes,Yes,The AI tool was compared to current standard practice (ie evaluation metrics on test set should be compared to same metrics for current clinical tests - so for example how did it compare to radiologists),No,No,No
2021_Peeken_Prognostic Assessment in High-Grade Soft-Tissue Sarcoma Patients: A Comparison of Semantic Image Analysis and Radiomics,No potential biases were discussed prior to AI development,"More than two attributes in the list were collected, OR with other attributes",Biases were investigated and reported,The clinical setting was not reported ,Yes,"Evaluation was performed using external dataset from one other site (or same source, eg public available);","local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, however intended use and end-user requirement was described; OR, multiple stakeholders were present for AI development, no intented use or requirement was decribed",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has not been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has been evaluated against real-world data (test data),Explainibility has not been defined at the design phase,Explainability has not been defined or not evaluated with end-users,Yes,Yes,The AI tool was compared to current standard practice (ie evaluation metrics on test set should be compared to same metrics for current clinical tests - so for example how did it compare to radiologists),No,No,No
2020_Pressney_Pilot study to differentiate lipoma from atypical lipomatous tumour/well-differentiated liposarcoma using MR radiomics-based texture analysis,No potential biases were discussed prior to AI development,"More than two attributes in the list were collected, OR with other attributes",Biases were investigated and reported,The clinical setting was not reported ,No,This study only used single center data --> no external validation;,"local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, however intended use and end-user requirement was described; OR, multiple stakeholders were present for AI development, no intented use or requirement was decribed",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has not been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has not been evaluated against real-world data (test data),Explainibility has not been defined at the design phase,Explainability has not been defined or not evaluated with end-users,Yes,Yes,Evaluation was not conducted using standardized and best practices,No,No,No
2021_Purnima_An Approach to Detect and Classify Bone tumour using fast and Robust Fuzzy C Means Clustering technique,No potential biases were discussed prior to AI development,No relevant attributes of the patient were collected;,Biases were neither investigated nor corrected for,The clinical setting was not reported ,No,This study only used single center data --> no external validation;,"local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, and no intended use and user requirement was described",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has not been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has not been evaluated against real-world data (test data),Explainibility has not been defined at the design phase,Explainability has not been defined or not evaluated with end-users,No,No,Evaluation was not conducted using standardized and best practices,No,No,No
2020_Ren_Development and validation of a nomogram based on CT images and 3D texture analysis for preoperative prediction of the malignant potential in gastrointestinal stromal tumors,No potential biases were discussed prior to AI development,"More than two attributes in the list were collected, OR with other attributes",Biases were investigated and reported,The clinical setting was not reported ,No,This study only used single center data --> no external validation;,"local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, and no intended use and user requirement was described",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has not been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has been evaluated against real-world data (test data),Explainibility has not been defined at the design phase,Explainability has not been defined or not evaluated with end-users,No,Yes,A seperate test set was used to evaluate the AI tool and reported on using appropriate evaluation metrics (eg sensitivity and specificity) ,No,No,No
2023_Rengo_Development and Validation of Artificial-Intelligence-Based Radiomics Model Using Computed Tomography Features for Preoperative Risk Stratification of Gastrointestinal Stromal Tumors,No potential biases were discussed prior to AI development,"More than two attributes in the list were collected, OR with other attributes",Biases were investigated and reported,The clinical setting was not reported ,No,This study only used single center data --> no external validation;,"local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, however intended use and end-user requirement was described; OR, multiple stakeholders were present for AI development, no intented use or requirement was decribed",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has not been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has been evaluated against real-world data (test data),Explainibility has not been defined at the design phase,Explainability has not been defined or not evaluated with end-users,Yes,Yes,A seperate test set was used to evaluate the AI tool and reported on using appropriate evaluation metrics (eg sensitivity and specificity) ,No,No,No
2022_Ristow_Evaluation of magnetic resonance imaging-based radiomics characteristics for differentiation of benign and malignant peripheral nerve sheath tumors in neurofibromatosis type 1,No potential biases were discussed prior to AI development,"At least the two attributes in the list collected; (list :sex OR gender, age, ethnicity, risk factors(as 1 item), comorbidities or disabilities)",Biases were neither investigated nor corrected for,The clinical setting was not reported ,No,This study only used single center data --> no external validation;,"local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, however intended use and end-user requirement was described; OR, multiple stakeholders were present for AI development, no intented use or requirement was decribed",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has not been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has not been evaluated against real-world data (test data),Explainibility has not been defined at the design phase,Explainability has not been defined or not evaluated with end-users,Yes,Yes,Evaluation was not conducted using standardized and best practices,No,No,No
2022_Seven_Use of Artificial Intelligence in the Prediction of Malignant Potential of Gastric Gastrointestinal Stromal Tumors,No potential biases were discussed prior to AI development,"More than two attributes in the list were collected, OR with other attributes",Biases were investigated and reported,The clinical setting was not reported ,No,This study only used single center data --> no external validation;,"local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, however intended use and end-user requirement was described; OR, multiple stakeholders were present for AI development, no intented use or requirement was decribed",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has not been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has been evaluated against real-world data (test data),Explainibility has not been defined at the design phase,Explainability has not been defined or not evaluated with end-users,Yes,Yes,A seperate test set was used to evaluate the AI tool and reported on using appropriate evaluation metrics (eg sensitivity and specificity) ,No,No,No
2021_Seven_Differentiating Gastrointestinal Stromal Tumors from Leiomyomas Using a Neural Network Trained on Endoscopic Ultrasonography Images,No potential biases were discussed prior to AI development,"More than two attributes in the list were collected, OR with other attributes","Biases were also corrected for by mitigation measures (In case of no biases found, 3 also applies)",The clinical setting was not reported ,No,This study only used single center data --> no external validation;,"local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, however intended use and end-user requirement was described; OR, multiple stakeholders were present for AI development, no intented use or requirement was decribed",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has not been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has been evaluated against real-world data (test data),Explainibility has not been defined at the design phase,Explainability has not been defined or not evaluated with end-users,Yes,Yes,The AI tool was compared to current standard practice (ie evaluation metrics on test set should be compared to same metrics for current clinical tests - so for example how did it compare to radiologists),No,No,No
2019_Sheen_Metastasis risk prediction model in osteosarcoma using metabolic imaging phenotypes: Amultivariable radiomics model,No potential biases were discussed prior to AI development,"More than two attributes in the list were collected, OR with other attributes",Biases were neither investigated nor corrected for,The clinical setting was not reported ,No,This study only used single center data --> no external validation;,"local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, however intended use and end-user requirement was described; OR, multiple stakeholders were present for AI development, no intented use or requirement was decribed",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has not been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has been evaluated against real-world data (test data),Explainibility has not been defined at the design phase,Explainability has not been defined or not evaluated with end-users,Yes,Yes,A seperate test set was used to evaluate the AI tool and reported on using appropriate evaluation metrics (eg sensitivity and specificity) ,No,No,No
2020_Singh_Bone Tumour detection Using Feature Extraction with Classification by Deep Learning Techniques,No potential biases were discussed prior to AI development,No relevant attributes of the patient were collected;,Biases were neither investigated nor corrected for,The clinical setting was not reported ,No,This study only used single center data --> no external validation;,"local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, however intended use and end-user requirement was described; OR, multiple stakeholders were present for AI development, no intented use or requirement was decribed",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has not been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has not been evaluated against real-world data (test data),Explainibility has not been defined at the design phase,Explainability has not been defined or not evaluated with end-users,Yes,No,Evaluation was not conducted using standardized and best practices,No,No,No
2019_Skorpil_Soft-tissue fat tumours: differentiating malignant from benign using proton density fat fraction quantification MRI,No potential biases were discussed prior to AI development,No relevant attributes of the patient were collected;,Biases were neither investigated nor corrected for,The clinical setting was not reported ,No,This study only used single center data --> no external validation;,"local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, however intended use and end-user requirement was described; OR, multiple stakeholders were present for AI development, no intented use or requirement was decribed",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has not been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has not been evaluated against real-world data (test data),Explainibility has not been defined at the design phase,Explainability has not been defined or not evaluated with end-users,Yes,Yes,Evaluation was not conducted using standardized and best practices,No,No,No
2021_Sun_A CT-based radiomics nomogram for distinguishing between benign and malignant bone tumours,No potential biases were discussed prior to AI development,"More than two attributes in the list were collected, OR with other attributes",Biases were investigated and reported,The clinical setting was not reported ,No,This study only used single center data --> no external validation;,"local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, however intended use and end-user requirement was described; OR, multiple stakeholders were present for AI development, no intented use or requirement was decribed",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has not been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has been evaluated against real-world data (test data),Explainibility has not been defined at the design phase,Explainability has not been defined or not evaluated with end-users,Yes,Yes,A seperate test set was used to evaluate the AI tool and reported on using appropriate evaluation metrics (eg sensitivity and specificity) ,No,No,No
2022_Sun_Preoperative prediction of malignant potential of 2-5 cm gastric gastrointestinal stromal tumors by computerized tomography-based radiomics,No potential biases were discussed prior to AI development,"More than two attributes in the list were collected, OR with other attributes",Biases were investigated and reported,The clinical setting was not reported ,No,This study only used single center data --> no external validation;,"local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, however intended use and end-user requirement was described; OR, multiple stakeholders were present for AI development, no intented use or requirement was decribed",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has not been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has been evaluated against real-world data (test data),Explainibility has not been defined at the design phase,Explainability has not been defined or not evaluated with end-users,Yes,Yes,A seperate test set was used to evaluate the AI tool and reported on using appropriate evaluation metrics (eg sensitivity and specificity) ,No,No,No
2019_Tagliafico_Local recurrence of soft tissue sarcoma: a radiomic analysis,No potential biases were discussed prior to AI development,"More than two attributes in the list were collected, OR with other attributes",Biases were neither investigated nor corrected for,The clinical setting was not reported ,No,This study only used single center data --> no external validation;,"local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, however intended use and end-user requirement was described; OR, multiple stakeholders were present for AI development, no intented use or requirement was decribed",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has not been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has not been evaluated against real-world data (test data),Explainibility has not been defined at the design phase,Explainability has not been defined or not evaluated with end-users,Yes,Yes,Evaluation was not conducted using standardized and best practices,No,No,No
2022_Tang_Differentiation Between Lipomas and Atypical Lipomatous Tumors of the Extremities Using Radiomics,No potential biases were discussed prior to AI development,"More than two attributes in the list were collected, OR with other attributes",Biases were neither investigated nor corrected for,The clinical setting was not reported ,No,This study only used single center data --> no external validation;,"local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, however intended use and end-user requirement was described; OR, multiple stakeholders were present for AI development, no intented use or requirement was decribed",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has not been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has been evaluated against real-world data (test data),Explainibility has not been defined at the design phase,Explainability has not been defined or not evaluated with end-users,Yes,Yes,The AI tool was compared to current standard practice (ie evaluation metrics on test set should be compared to same metrics for current clinical tests - so for example how did it compare to radiologists),No,No,No
2022_Teo_Correlation of histopathology and multi-modal magnetic resonance imaging in childhood osteosarcoma: Predicting tumor response to chemotherapy,No potential biases were discussed prior to AI development,"At least the two attributes in the list collected; (list :sex OR gender, age, ethnicity, risk factors(as 1 item), comorbidities or disabilities)",Biases were neither investigated nor corrected for,The clinical setting was not reported ,No,This study only used single center data --> no external validation;,"local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, however intended use and end-user requirement was described; OR, multiple stakeholders were present for AI development, no intented use or requirement was decribed",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has not been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has not been evaluated against real-world data (test data),Explainibility has not been defined at the design phase,Explainability has not been defined or not evaluated with end-users,Yes,Yes,Evaluation was not conducted using standardized and best practices,No,No,No
2021_Tian_Radiomics-based machine-learning method for prediction of distant metastasis from soft-tissue sarcomas,No potential biases were discussed prior to AI development,"More than two attributes in the list were collected, OR with other attributes",Biases were investigated and reported,The clinical setting was not reported ,No,This study only used single center data --> no external validation;,"local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, however intended use and end-user requirement was described; OR, multiple stakeholders were present for AI development, no intented use or requirement was decribed",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has not been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has been evaluated against real-world data (test data),Explainibility has not been defined at the design phase,Explainability has not been defined or not evaluated with end-users,Yes,Yes,A seperate test set was used to evaluate the AI tool and reported on using appropriate evaluation metrics (eg sensitivity and specificity) ,No,No,No
2021_Wilhelm_Multitask Deep Learning for Segmentation and Classification of Primary Bone Tumors on Radiographs,No potential biases were discussed prior to AI development,No relevant attributes of the patient were collected;,Biases were neither investigated nor corrected for,The clinical setting was not reported ,No,"Evaluation was performed using external dataset from one other site (or same source, eg public available);","local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, however intended use and end-user requirement was described; OR, multiple stakeholders were present for AI development, no intented use or requirement was decribed",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has not been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has been evaluated against real-world data (test data),Explainibility has not been defined at the design phase,Explainability has not been defined or not evaluated with end-users,Yes,Yes,The AI tool was compared to current standard practice (ie evaluation metrics on test set should be compared to same metrics for current clinical tests - so for example how did it compare to radiologists),No,No,No
2019_Vos_Radiomics approach to distinguish between well differentiated liposarcomas and lipomas on MRI,No potential biases were discussed prior to AI development,"More than two attributes in the list were collected, OR with other attributes",Biases were neither investigated nor corrected for,The clinical setting was not reported ,No,"Evaluation was performed using external dataset from one other site (or same source, eg public available);","local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, however intended use and end-user requirement was described; OR, multiple stakeholders were present for AI development, no intented use or requirement was decribed",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has not been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has been evaluated against real-world data (test data),Explainibility has not been defined at the design phase,Explainability has not been defined or not evaluated with end-users,Yes,Yes,The AI tool was compared to current standard practice (ie evaluation metrics on test set should be compared to same metrics for current clinical tests - so for example how did it compare to radiologists),No,No,No
2020_Abdel Wahab_Diagnostic Algorithm to Differentiate Benign Atypical Leiomyomas from                    Malignant Uterine Sarcomas with Diffusion-weighted MRI,No potential biases were discussed prior to AI development,"More than two attributes in the list were collected, OR with other attributes",Biases were neither investigated nor corrected for,The clinical setting was not reported ,Yes,Evaluation was performed using external dataset from multiple sites;,"local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, however intended use and end-user requirement was described; OR, multiple stakeholders were present for AI development, no intented use or requirement was decribed",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has not been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has been evaluated against real-world data (test data),Explainibility has not been defined at the design phase,Explainability has not been defined or not evaluated with end-users,Yes,Yes,A seperate test set was used to evaluate the AI tool and reported on using appropriate evaluation metrics (eg sensitivity and specificity) ,No,No,No
2020_Wang_Radiomics and Machine Learning With Multiparametric Preoperative MRI May Accurately Predict the Histopathological Grades of Soft Tissue Sarcomas,No potential biases were discussed prior to AI development,"More than two attributes in the list were collected, OR with other attributes",Biases were investigated and reported,The clinical setting was not reported ,No,"Evaluation was performed using external dataset from one other site (or same source, eg public available);","local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, however intended use and end-user requirement was described; OR, multiple stakeholders were present for AI development, no intented use or requirement was decribed",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has not been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has been evaluated against real-world data (test data),Explainibility has not been defined at the design phase,Explainability has not been defined or not evaluated with end-users,Yes,Yes,A seperate test set was used to evaluate the AI tool and reported on using appropriate evaluation metrics (eg sensitivity and specificity) ,No,No,No
2020_Wang_Radiomics nomogram for differentiating between benign and malignant soft-tissue masses of the extremities,No potential biases were discussed prior to AI development,"More than two attributes in the list were collected, OR with other attributes",Biases were investigated and reported,The clinical setting was not reported ,No,This study only used single center data --> no external validation;,"local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, however intended use and end-user requirement was described; OR, multiple stakeholders were present for AI development, no intented use or requirement was decribed",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has not been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has not been evaluated against real-world data (test data),Explainibility has not been defined at the design phase,Explainability has not been defined or not evaluated with end-users,Yes,Yes,A seperate test set was used to evaluate the AI tool and reported on using appropriate evaluation metrics (eg sensitivity and specificity) ,No,No,No
2020_Wang_Preoperative MRI-Based Radiomic Machine-Learning Nomogram May Accurately Distinguish Between Benign and Malignant Soft-Tissue Lesions: A Two-Center Study,No potential biases were discussed prior to AI development,"At least the two attributes in the list collected; (list :sex OR gender, age, ethnicity, risk factors(as 1 item), comorbidities or disabilities)",Biases were investigated and reported,The clinical setting was not reported ,No,"Evaluation was performed using external dataset from one other site (or same source, eg public available);","local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, however intended use and end-user requirement was described; OR, multiple stakeholders were present for AI development, no intented use or requirement was decribed",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has not been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has been evaluated against real-world data (test data) and the AI tool's robustness has been optimized (if applicable) using mitigation methods,Explainibility has not been defined at the design phase,Explainability has not been defined or not evaluated with end-users,Yes,Yes,A seperate test set was used to evaluate the AI tool and reported on using appropriate evaluation metrics (eg sensitivity and specificity) ,No,No,No
2021_Wang_Computed-Tomography-Based Radiomics Model for Predicting the Malignant Potential of Gastrointestinal Stromal Tumors Preoperatively: A Multi-Classifier and Multicenter Study,No potential biases were discussed prior to AI development,"More than two attributes in the list were collected, OR with other attributes",Biases were investigated and reported,The clinical setting was not reported ,No,"Evaluation was performed using external dataset from one other site (or same source, eg public available);","local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, however intended use and end-user requirement was described; OR, multiple stakeholders were present for AI development, no intented use or requirement was decribed",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has not been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has been evaluated against real-world data (test data),Explainibility has not been defined at the design phase,Explainability has not been defined or not evaluated with end-users,Yes,Yes,A seperate test set was used to evaluate the AI tool and reported on using appropriate evaluation metrics (eg sensitivity and specificity) ,No,No,No
2020_Wei_Computed Tomography-Based Differentiation of Benign and Malignant Craniofacial Lesions in Neurofibromatosis Type I Patients: A Machine Learning Approach,No potential biases were discussed prior to AI development,"At least the two attributes in the list collected; (list :sex OR gender, age, ethnicity, risk factors(as 1 item), comorbidities or disabilities)",Biases were neither investigated nor corrected for,The clinical setting was not reported ,No,"Evaluation was performed using external dataset from one other site (or same source, eg public available);","local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, however intended use and end-user requirement was described; OR, multiple stakeholders were present for AI development, no intented use or requirement was decribed",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has not been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has been evaluated against real-world data (test data),Explainibility has not been defined at the design phase,Explainability has not been defined or not evaluated with end-users,Yes,Yes,A seperate test set was used to evaluate the AI tool and reported on using appropriate evaluation metrics (eg sensitivity and specificity) ,No,No,No
2020_Xu_Bone tumor necrosis rate detection in few-shot X-rays based on deep learning,No potential biases were discussed prior to AI development,"At least the two attributes in the list collected; (list :sex OR gender, age, ethnicity, risk factors(as 1 item), comorbidities or disabilities)",Biases were neither investigated nor corrected for,The clinical setting was not reported ,No,This study only used single center data --> no external validation;,"local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, however intended use and end-user requirement was described; OR, multiple stakeholders were present for AI development, no intented use or requirement was decribed",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has not been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has been evaluated against real-world data (test data),Explainibility has not been defined at the design phase,Explainability has not been defined or not evaluated with end-users,Yes,No,A seperate test set was used to evaluate the AI tool and reported on using appropriate evaluation metrics (eg sensitivity and specificity) ,No,No,No
2021_Yan_Magnetic Resonance Imaging-Based Radiomics Nomogram for Prediction of the Histopathological Grade of Soft Tissue Sarcomas: A Two-Center Study,No potential biases were discussed prior to AI development,"More than two attributes in the list were collected, OR with other attributes","Biases were also corrected for by mitigation measures (In case of no biases found, 3 also applies)",The clinical setting was not reported ,No,"Evaluation was performed using external dataset from one other site (or same source, eg public available);","local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, however intended use and end-user requirement was described; OR, multiple stakeholders were present for AI development, no intented use or requirement was decribed",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has not been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has been evaluated against real-world data (test data) and the AI tool's robustness has been optimized (if applicable) using mitigation methods,Explainibility has not been defined at the design phase,Explainability has not been defined or not evaluated with end-users,Yes,Yes,A seperate test set was used to evaluate the AI tool and reported on using appropriate evaluation metrics (eg sensitivity and specificity) ,No,No,No
2022_Yang_An artificial intelligence system for distinguishing between gastrointestinal stromal tumors and leiomyomas using endoscopic ultrasonography,No potential biases were discussed prior to AI development,"More than two attributes in the list were collected, OR with other attributes",Biases were neither investigated nor corrected for,The clinical setting was not reported ,No,Evaluation was performed using external dataset from multiple sites;,"local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool provides at least one interface or human-in-the-loop mechanism to involve human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, however intended use and end-user requirement was described; OR, multiple stakeholders were present for AI development, no intented use or requirement was decribed",No,The AI tool was evaluated for user experience by multiple independent end-users,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has not been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has been evaluated against real-world data (test data),Explainibility has not been defined at the design phase,Explainability has not been defined or not evaluated with end-users,Yes,Yes,A seperate test set was used to evaluate the AI tool and reported on using appropriate evaluation metrics (eg sensitivity and specificity) ,No,No,No
2023_Yan_MRI Fat-Saturated T2-Weighted Radiomics Model for Identifying the Ki-67 Index of Soft Tissue Sarcomas,No potential biases were discussed prior to AI development,"More than two attributes in the list were collected, OR with other attributes",Biases were investigated and reported,The clinical setting was not reported ,No,"Evaluation was performed using external dataset from one other site (or same source, eg public available);","local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, however intended use and end-user requirement was described; OR, multiple stakeholders were present for AI development, no intented use or requirement was decribed",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has not been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has been evaluated against real-world data (test data) and the AI tool's robustness has been optimized (if applicable) using mitigation methods,Explainibility has not been defined at the design phase,Explainability has not been defined or not evaluated with end-users,Yes,Yes,A seperate test set was used to evaluate the AI tool and reported on using appropriate evaluation metrics (eg sensitivity and specificity) ,No,No,No
2022_Yang_Novel computer aided diagnostic models on multimodality medical images to differentiate well differentiated liposarcomas from lipomas approached by deep learning methods,No potential biases were discussed prior to AI development,"More than two attributes in the list were collected, OR with other attributes",Biases were investigated and reported,The clinical setting was not reported ,Yes,"Evaluation was performed using external dataset from one other site (or same source, eg public available);","local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, however intended use and end-user requirement was described; OR, multiple stakeholders were present for AI development, no intented use or requirement was decribed",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has not been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has been evaluated against real-world data (test data),"At least one of the following areas is discussed: (i) the goal of the explanations (eg global description of the model’s behaviour vs local explanation of each AI decision), (ii) the most suitable approach for AI explainability and (iii) the potential limitations to anticipate and monitor (eg over-reliance of the end-users on the AI decision)",Explainability has not been defined or not evaluated with end-users,Yes,Yes,A seperate test set was used to evaluate the AI tool and reported on using appropriate evaluation metrics (eg sensitivity and specificity) ,No,No,No
2022_Yang_MRI-Based Computer-Aided Diagnostic Model to Predict Tumor Grading and Clinical Outcomes in Patients With Soft Tissue Sarcoma,No potential biases were discussed prior to AI development,"More than two attributes in the list were collected, OR with other attributes",Biases were neither investigated nor corrected for,The clinical setting was not reported ,Yes,This study only used single center data --> no external validation;,"local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, however intended use and end-user requirement was described; OR, multiple stakeholders were present for AI development, no intented use or requirement was decribed",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has not been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has been evaluated against real-world data (test data) and the AI tool's robustness has been optimized (if applicable) using mitigation methods,"At least one of the following areas is discussed: (i) the goal of the explanations (eg global description of the model’s behaviour vs local explanation of each AI decision), (ii) the most suitable approach for AI explainability and (iii) the potential limitations to anticipate and monitor (eg over-reliance of the end-users on the AI decision)",Explainability has not been defined or not evaluated with end-users,Yes,Yes,A seperate test set was used to evaluate the AI tool and reported on using appropriate evaluation metrics (eg sensitivity and specificity) ,No,No,No
2020_Yin_Can clinical radiomics nomogram based on 3D multiparametric MRI features and clinical characteristics estimate early recurrence of pelvic chondrosarcoma?,"Potential biases in at least 1 group (group attributes, medical profile, human biases) were discussed prior to AI development","More than two attributes in the list were collected, OR with other attributes",Biases were investigated and reported,The clinical setting was not reported ,No,This study only used single center data --> no external validation;,"local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, however intended use and end-user requirement was described; OR, multiple stakeholders were present for AI development, no intented use or requirement was decribed",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has not been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has been evaluated against real-world data (test data),Explainibility has not been defined at the design phase,Explainability has not been defined or not evaluated with end-users,Yes,Yes,A seperate test set was used to evaluate the AI tool and reported on using appropriate evaluation metrics (eg sensitivity and specificity) ,No,No,No
"2019_Yin_A Triple-Classification Radiomics Model for the Differentiation of Primary Chordoma, Giant Cell Tumor, and Metastatic Tumor of Sacrum Based on T2-Weighted and Contrast-Enhanced T1-Weighted MRI",No potential biases were discussed prior to AI development,"At least the two attributes in the list collected; (list :sex OR gender, age, ethnicity, risk factors(as 1 item), comorbidities or disabilities)",Biases were investigated and reported,The clinical setting was not reported ,No,This study only used single center data --> no external validation;,"local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, however intended use and end-user requirement was described; OR, multiple stakeholders were present for AI development, no intented use or requirement was decribed",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has not been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has been evaluated against real-world data (test data),Explainibility has not been defined at the design phase,Explainability has not been defined or not evaluated with end-users,Yes,Yes,A seperate test set was used to evaluate the AI tool and reported on using appropriate evaluation metrics (eg sensitivity and specificity) ,No,No,No
2021_Yin_Clinical-Deep Neural Network and Clinical-Radiomics Nomograms for Predicting the Intraoperative Massive Blood Loss of Pelvic and Sacral Tumors,No potential biases were discussed prior to AI development,"More than two attributes in the list were collected, OR with other attributes",Biases were investigated and reported,The clinical setting was not reported ,No,This study only used single center data --> no external validation;,"local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, however intended use and end-user requirement was described; OR, multiple stakeholders were present for AI development, no intented use or requirement was decribed",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has not been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has not been evaluated against real-world data (test data),Explainibility has not been defined at the design phase,Explainability has not been defined or not evaluated with end-users,Yes,Yes,A seperate test set was used to evaluate the AI tool and reported on using appropriate evaluation metrics (eg sensitivity and specificity) ,No,No,No
2023_Zhang_Machine learning for predicting the risk stratification of 1-5 cm gastric gastrointestinal stromal tumors based on CT,No potential biases were discussed prior to AI development,"More than two attributes in the list were collected, OR with other attributes",Biases were investigated and reported,The clinical setting was not reported ,No,"Evaluation was performed using external dataset from one other site (or same source, eg public available);","local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, and no intended use and user requirement was described",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has not been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has been evaluated against real-world data (test data),"At least one of the following areas is discussed: (i) the goal of the explanations (eg global description of the model’s behaviour vs local explanation of each AI decision), (ii) the most suitable approach for AI explainability and (iii) the potential limitations to anticipate and monitor (eg over-reliance of the end-users on the AI decision)",Explainability has not been defined or not evaluated with end-users,Yes,Yes,The AI tool was compared to current standard practice (ie evaluation metrics on test set should be compared to same metrics for current clinical tests - so for example how did it compare to radiologists),No,No,No
2020_Zhang_Comparison of CT and MRI images for the prediction of soft-tissue sarcoma grading and lung metastasis via a convolutional neural networks model,No potential biases were discussed prior to AI development,"More than two attributes in the list were collected, OR with other attributes",Biases were neither investigated nor corrected for,The clinical setting was not reported ,No,This study only used single center data --> no external validation;,"local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, however intended use and end-user requirement was described; OR, multiple stakeholders were present for AI development, no intented use or requirement was decribed",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has not been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has been evaluated against real-world data (test data),Explainibility has not been defined at the design phase,Explainability has not been defined or not evaluated with end-users,Yes,Yes,A seperate test set was used to evaluate the AI tool and reported on using appropriate evaluation metrics (eg sensitivity and specificity) ,No,No,No
2021_Zhang_Machine-Learning Approach to Differentiation of Benign and Malignant Peripheral Nerve Sheath Tumors: A Multicenter Study,No potential biases were discussed prior to AI development,"More than two attributes in the list were collected, OR with other attributes",Biases were investigated and reported,The clinical setting was not reported ,Yes,Evaluation was performed using external dataset from multiple sites;,"local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, however intended use and end-user requirement was described; OR, multiple stakeholders were present for AI development, no intented use or requirement was decribed",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has not been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has been evaluated against real-world data (test data),Explainibility has not been defined at the design phase,Explainability has not been defined or not evaluated with end-users,Yes,Yes,The AI tool was compared to current standard practice (ie evaluation metrics on test set should be compared to same metrics for current clinical tests - so for example how did it compare to radiologists),No,No,No
2022_Zhang_Machine learning approach to differentiation of peripheral schwannomas and neurofibromas: A multi-center study,No potential biases were discussed prior to AI development,"More than two attributes in the list were collected, OR with other attributes",Biases were investigated and reported,The clinical setting was not reported ,No,Evaluation was performed using external dataset from multiple sites;,"local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, however intended use and end-user requirement was described; OR, multiple stakeholders were present for AI development, no intented use or requirement was decribed",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has not been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has been evaluated against real-world data (test data),Explainibility has not been defined at the design phase,Explainability has not been defined or not evaluated with end-users,Yes,Yes,The AI tool was compared to current standard practice (ie evaluation metrics on test set should be compared to same metrics for current clinical tests - so for example how did it compare to radiologists),No,No,No
2020_Zhang_Personalized CT-based radiomics nomogram preoperative predicting Ki-67 expression in gastrointestinal stromal tumors: a multicenter development and validation cohort,No potential biases were discussed prior to AI development,"More than two attributes in the list were collected, OR with other attributes",Biases were investigated and reported,The clinical setting was not reported ,No,Evaluation was performed using external dataset from multiple sites;,"local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, however intended use and end-user requirement was described; OR, multiple stakeholders were present for AI development, no intented use or requirement was decribed",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has not been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has been evaluated against real-world data (test data),Explainibility has not been defined at the design phase,Explainability has not been defined or not evaluated with end-users,Yes,Yes,A seperate test set was used to evaluate the AI tool and reported on using appropriate evaluation metrics (eg sensitivity and specificity) ,No,No,No
2023_Zhang_A combined radiomic model distinguishing GISTs from leiomyomas and schwannomas in the stomach based on endoscopic ultrasonography images,No potential biases were discussed prior to AI development,"More than two attributes in the list were collected, OR with other attributes",Biases were investigated and reported,The clinical setting was not reported ,No,Evaluation was performed using external dataset from multiple sites;,"local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, however intended use and end-user requirement was described; OR, multiple stakeholders were present for AI development, no intented use or requirement was decribed",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has not been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has been evaluated against real-world data (test data),Explainibility has not been defined at the design phase,Explainability has not been defined or not evaluated with end-users,Yes,Yes,The AI tool was compared to current standard practice (ie evaluation metrics on test set should be compared to same metrics for current clinical tests - so for example how did it compare to radiologists),No,No,No
2022_Zhang_Diagnostic Performance of Dynamic Contrast-Enhanced MRI and 18F-FDG PET/CT for Evaluation of Soft Tissue Tumors and Correlation with Pathology Parameters,No potential biases were discussed prior to AI development,No relevant attributes of the patient were collected;,Biases were neither investigated nor corrected for,The clinical setting was not reported ,No,This study only used single center data --> no external validation;,"local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, however intended use and end-user requirement was described; OR, multiple stakeholders were present for AI development, no intented use or requirement was decribed",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has not been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has not been evaluated against real-world data (test data),Explainibility has not been defined at the design phase,Explainability has not been defined or not evaluated with end-users,Yes,Yes,Evaluation was not conducted using standardized and best practices,No,No,No
2022_Zhao_Deep Learning Assisted Diagnosis of Musculoskeletal Tumors Based on Contrast-Enhanced Magnetic Resonance Imaging,No potential biases were discussed prior to AI development,"More than two attributes in the list were collected, OR with other attributes",Biases were investigated and reported,The clinical setting was not reported ,No,This study only used single center data --> no external validation;,"local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, however intended use and end-user requirement was described; OR, multiple stakeholders were present for AI development, no intented use or requirement was decribed",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has not been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has been evaluated against real-world data (test data),"At least one of the following areas is discussed: (i) the goal of the explanations (eg global description of the model’s behaviour vs local explanation of each AI decision), (ii) the most suitable approach for AI explainability and (iii) the potential limitations to anticipate and monitor (eg over-reliance of the end-users on the AI decision)",Explainability has not been defined or not evaluated with end-users,Yes,Yes,The AI tool was compared to current standard practice (ie evaluation metrics on test set should be compared to same metrics for current clinical tests - so for example how did it compare to radiologists),No,No,No
2023_George_Adaptive FLAME based segmentation and classification for bone cancer detection,No potential biases were discussed prior to AI development,No relevant attributes of the patient were collected;,Biases were neither investigated nor corrected for,The clinical setting was not reported ,No,This study only used single center data --> no external validation;,"local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, and no intended use and user requirement was described",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has not been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has not been evaluated against real-world data (test data),Explainibility has not been defined at the design phase,Explainability has not been defined or not evaluated with end-users,No,No,A seperate test set was used to evaluate the AI tool and reported on using appropriate evaluation metrics (eg sensitivity and specificity) ,No,No,No
2021_Georgaunu_Convolutional Neural Networks for Automated Detection and Classification of Bone Tumors in Magnetic Resonance Imaging,No potential biases were discussed prior to AI development,No relevant attributes of the patient were collected;,Biases were neither investigated nor corrected for,The clinical setting was not reported ,No,This study only used single center data --> no external validation;,"local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, however intended use and end-user requirement was described; OR, multiple stakeholders were present for AI development, no intented use or requirement was decribed",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has not been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has been evaluated against real-world data (test data),Explainibility has not been defined at the design phase,Explainability has not been defined or not evaluated with end-users,Yes,No,A seperate test set was used to evaluate the AI tool and reported on using appropriate evaluation metrics (eg sensitivity and specificity) ,No,No,No
2022_Jayachandran_X-Ray Image Analysis in Identification of Bone Cancer Using Laws Features and Machine Learning Model,No potential biases were discussed prior to AI development,No relevant attributes of the patient were collected;,Biases were neither investigated nor corrected for,The clinical setting was not reported ,No,This study only used single center data --> no external validation;,"local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, and no intended use and user requirement was described",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has not been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has been evaluated against real-world data (test data),Explainibility has not been defined at the design phase,Explainability has not been defined or not evaluated with end-users,No,No,A seperate test set was used to evaluate the AI tool and reported on using appropriate evaluation metrics (eg sensitivity and specificity) ,No,No,No
2023_Lingappa_Image Classification with Deep Learning Methods for Detecting and Staging Bone Cancer from MRI,No potential biases were discussed prior to AI development,No relevant attributes of the patient were collected;,Biases were neither investigated nor corrected for,The clinical setting was not reported ,No,This study only used single center data --> no external validation;,"local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, however intended use and end-user requirement was described; OR, multiple stakeholders were present for AI development, no intented use or requirement was decribed",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has not been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has not been evaluated against real-world data (test data),Explainibility has not been defined at the design phase,Explainability has not been defined or not evaluated with end-users,Yes,No,Evaluation was not conducted using standardized and best practices,No,No,No
2021_Alaoui_Improvement in automated diagnosis of soft tissues tumors using machine learning,No potential biases were discussed prior to AI development,"More than two attributes in the list were collected, OR with other attributes",Biases were neither investigated nor corrected for,The clinical setting was not reported ,No,This study only used single center data --> no external validation;,"local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,"Only 1 type of stakeholder (eg AI developers/departments) was present for AI development, however intended use and end-user requirement was described; OR, multiple stakeholders were present for AI development, no intented use or requirement was decribed",No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has not been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has been evaluated against real-world data (test data),Explainibility has not been defined at the design phase,Explainability has not been defined or not evaluated with end-users,Yes,No,A seperate test set was used to evaluate the AI tool and reported on using appropriate evaluation metrics (eg sensitivity and specificity) ,No,No,No
2023_Zhu_Radiomics model based on intravoxel incoherent motion and diffusion kurtosis imaging for predicting histopathological grade and Ki-67 expression level of soft tissue sarcomas,No potential biases were discussed prior to AI development,"At least the two attributes in the list collected; (list :sex OR gender, age, ethnicity, risk factors(as 1 item), comorbidities or disabilities)",Biases were neither investigated nor corrected for,The clinical setting was not reported ,No,This study only used single center data --> no external validation;,"local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,Multiple stakeholders were present for AI development and compiled information on the AI tool’s intended use and end-user requirements,No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has not been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has been evaluated against real-world data (test data),Explainibility has not been defined at the design phase,Explainability has not been defined or not evaluated with end-users,Yes,Yes,A seperate test set was used to evaluate the AI tool and reported on using appropriate evaluation metrics (eg sensitivity and specificity) ,No,No,No
2023_Wang_Development of clinical and magnetic resonance imaging-based radiomics nomograms for the differentiation of nodular fasciitis from soft tissue sarcoma,No potential biases were discussed prior to AI development,"More than two attributes in the list were collected, OR with other attributes",Biases were neither investigated nor corrected for,The clinical setting was not reported ,No,This study only used single center data --> no external validation;,"local clinical validity has not been discussed, or was not applicable (eg AI tool was not deployed outside of research setting/externally) ",Risks regarding the AI lifecycle have not been described,No documentation has been provided,No monitoring or quality control measures of either inputs or outputs have beenimplemented ,No discussion of audit or future updating,No system has been devised for logging usage of the AI tool,The AI tool has no human oversight,Multiple stakeholders were present for AI development and compiled information on the AI tool’s intended use and end-user requirements,No,The AI tool was not evaluated for user experience,The AI tool was not evaluated for clinical utility and safety ,Data acquisiton and possible variation of the data source to the real world has not been discussed,The representative of the training data to the real-world data was not evaluated,The AI tool has been evaluated against real-world data (test data),Explainibility has not been defined at the design phase,Explainability has not been defined or not evaluated with end-users,Yes,Yes,A seperate test set was used to evaluate the AI tool and reported on using appropriate evaluation metrics (eg sensitivity and specificity) ,No,No,No
